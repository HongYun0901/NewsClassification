{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW ##新ㄉ 好像比較好\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 5\n",
    "# for train\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60000筆 0.9,0.05,0.05切\n",
    "data = pd.read_csv('./test_fix.csv')\n",
    "data_y = data['type'].tolist()\n",
    "data_x = data['text']\n",
    "\n",
    "train_x = data_x[:54000].tolist()\n",
    "train_y = np.array(data_y[:54000])\n",
    "\n",
    "test_x = data_x[54000:57000].tolist()\n",
    "test_y = np.array(data_y[54000:57000])\n",
    "\n",
    "dev_x = data_x[57000:].tolist()\n",
    "dev_y = np.array(data_y[57000:])\n",
    "\n",
    "#先用原本的bert\n",
    "model_path = '../chinese_wwm_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,input_dict,y):\n",
    "        self.self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "    def __getitem__(self, idx):\n",
    "        input_id = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        y = self.y[idx]\n",
    "        return input_id, tokentype, attentionmask, y\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "train_input = tokenizer.batch_encode_plus(train_x,\n",
    "                                          add_special_tokens = True,\n",
    "                                          max_length = 512,\n",
    "                                          truncation = True,                ##是否截斷\n",
    "                                          return_special_tokens_mask = True,\n",
    "                                          pad_to_max_length = True,\n",
    "                                          return_tensors = 'pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
