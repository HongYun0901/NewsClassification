{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.layers import Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Add,Concatenate,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#參數\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "\n",
    "\n",
    "print (keras.__version__)\n",
    "\n",
    "column_names = ['type','title','text']\n",
    "df = pd.read_csv('./all_after_mapping.tsv',sep='\\t',names=column_names)\n",
    "labels = df['type'].values\n",
    "labels = np.array(labels)\n",
    "print(labels)\n",
    "labels = np_utils.to_categorical(labels)\n",
    "print(labels.shape)\n",
    "tokenlizeword = np.load('./tokenlizeword0225_nopunct.npy',allow_pickle=True)\n",
    "# wmodel = Word2Vec(tokenlizeword, size=300, window=5, min_count=0)\n",
    "wmodel=Word2Vec.load('./word2vec.model')\n",
    "print(wmodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_train=文章數*最大字數*300維\n",
    "x_train = []\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "# every article have 每篇文章最多幾個字 * 300維 embedding matrix\n",
    "    embedding_matrix = np.zeros((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))\n",
    "    for i in range(len(tokenlizeword[k])):\n",
    "        if(i>=MAX_SEQUENCE_LENGTH):\n",
    "            break\n",
    "        embedding_matrix[i] = wmodel[tokenlizeword[k][i]]\n",
    "    x_train.append(embedding_matrix)\n",
    "\n",
    "print(\"embedding done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "\n",
    "\n",
    "dev_x = x_train[:5000]\n",
    "dev_y = labels[:5000]\n",
    "\n",
    "test_x = x_train[5000:10000]\n",
    "test_y = labels[5000:10000]\n",
    "\n",
    "train_x = x_train[10000:]\n",
    "train_y = labels[10000:]\n",
    "# !ls\n",
    "print(dev_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_x.shape)\n",
    "\n",
    "print(\"60%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "l_cov1= Conv1D(300, 3, activation='relu')(sequence_input)\n",
    "l_pool1 = MaxPooling1D(3)(l_cov1)\n",
    "l_drop1 = Dropout(0.5)(l_pool1)\n",
    "l_cov2 = Conv1D(300, 3, activation='relu')(l_drop1)\n",
    "l_pool2 = MaxPooling1D(3)(l_cov2)\n",
    "l_cov3 = Conv1D(300, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(3)(l_cov3)  # global max pooling\n",
    "l_drop2 = Dropout(0.5)(l_pool3)\n",
    "l_flat = Flatten()(l_drop2)\n",
    "\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(7, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adamax',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - simplified convolutional neural network\")\n",
    "model.summary()\n",
    "model.fit(train_x, train_y, validation_data = (dev_x,dev_y),epochs=10, batch_size=50)\n",
    "# model.fit(train_x, train_y, validation_split = 0.2,epochs=5, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_x,batch_size=50)\n",
    "pred=np.argmax(pred, axis=1)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#驗證\n",
    "correct=0 #對的有幾個\n",
    "for i in range(5000):\n",
    "    if test_y[i][pred[i]]==1.0:\n",
    "        correct = correct+1\n",
    "print(correct)\n",
    "acc=correct/5000\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=300, kernel_size=3)`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=300, kernel_size=4)`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=300, kernel_size=5)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - simplified convolutional neural network\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 512, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 510, 300)     270300      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 509, 300)     360300      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 508, 300)     450300      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 102, 300)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 101, 300)     0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 101, 300)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 102, 300)     0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 101, 300)     0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 101, 300)     0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 304, 300)     0           dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 300, 300)     450300      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 60, 300)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 56, 300)      450300      max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 11, 300)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 7, 300)       450300      max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1, 300)       0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 300)          0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          90300       flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 7)            2107        dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,524,207\n",
      "Trainable params: 2,524,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 25546 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "25546/25546 [==============================] - 211s 8ms/step - loss: 4.4179 - acc: 0.7435 - val_loss: 0.6597 - val_acc: 0.7854\n",
      "Epoch 2/3\n",
      "25546/25546 [==============================] - 210s 8ms/step - loss: 0.3633 - acc: 0.8779 - val_loss: 0.6126 - val_acc: 0.8070\n",
      "Epoch 3/3\n",
      "25546/25546 [==============================] - 210s 8ms/step - loss: 0.2891 - acc: 0.9003 - val_loss: 0.6124 - val_acc: 0.8058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc3f42fff98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#有不同sizeㄉ\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(nb_filter=300,filter_length=fsz,activation='relu')(sequence_input)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    l_drop = Dropout(0.2)(l_pool)\n",
    "    convs.append(l_drop)\n",
    "\n",
    "l_add = Concatenate(axis=1)(convs)\n",
    "l_cov1= Conv1D(300, 5, activation='relu')(l_add)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(300, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_cov3 = Conv1D(300, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(300, activation='relu')(l_flat)\n",
    "preds = Dense(7, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - simplified convolutional neural network\")\n",
    "model.summary()\n",
    "model.fit(train_x, train_y, validation_data = (test_x,test_y),epochs=3, batch_size=50)\n",
    "# model.fit(train_x, train_y, validation_split = 0.2,epochs=5, batch_size=128)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
