{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "[0 0 2 ... 3 6 2]\n",
      "(35546, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.layers import Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Add,Concatenate,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#參數\n",
    "MAX_SENT_LENGTH = 8\n",
    "MAX_SENTS = 128\n",
    "EMBEDDING_DIM = 250\n",
    "\n",
    "\n",
    "## label data\n",
    "\n",
    "print (keras.__version__)\n",
    "\n",
    "column_names = ['type','title','text']\n",
    "df = pd.read_csv('./all_after_mapping.tsv',sep='\\t',names=column_names)\n",
    "\n",
    "labels = df['type'].values\n",
    "labels = np.array(labels)\n",
    "print(labels)\n",
    "labels = np_utils.to_categorical(labels)\n",
    "print(labels.shape)\n",
    "tokenlizeword = np.load('./tokenlizeword0221.npy',allow_pickle=True)\n",
    "u_tokenlizeword = np.load('./tokenlizeword0226_udn_for_mct.npy',allow_pickle=True)\n",
    "#串起來\n",
    "tokenlizeword=np.concatenate((tokenlizeword, u_tokenlizeword), axis=0)\n",
    "\n",
    "wmodel = Word2Vec(tokenlizeword, size=EMBEDDING_DIM, window=10, min_count=20)\n",
    "# wmodel=Word2Vec.load('./word2vec.model')\n",
    "# wmodel.most_similar('我')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32947\n"
     ]
    }
   ],
   "source": [
    "vocab = wmodel.wv.vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46237\n",
      "embedding done\n"
     ]
    }
   ],
   "source": [
    "#x_train=文章數*最大句數*最大字數*300維\n",
    "x_train =[] #label data\n",
    "##文章數\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "    embedding_matrix=np.zeros((MAX_SENTS,MAX_SENT_LENGTH,EMBEDDING_DIM))\n",
    "    word_count=0 ##計算目前位置\n",
    "    ##句子數\n",
    "    for i in range(MAX_SENTS):\n",
    "        if word_count >= len(tokenlizeword[k]):\n",
    "            break\n",
    "        embedding_vector=np.zeros((MAX_SENT_LENGTH,EMBEDDING_DIM))\n",
    "        ##最大字數\n",
    "        for j in range(MAX_SENT_LENGTH):\n",
    "            if tokenlizeword[k][word_count] == '，' or tokenlizeword[k][word_count] == '。' or tokenlizeword[k][word_count] == '！' or tokenlizeword[k][word_count] == '？':\n",
    "                word_count=word_count+1\n",
    "                break\n",
    "            else:\n",
    "                if tokenlizeword[k][word_count] in vocab: ##在字典裡\n",
    "                    embedding_vector[j]=wmodel[tokenlizeword[k][word_count]]\n",
    "                word_count=word_count+1\n",
    "                if word_count >= len(tokenlizeword[k]):\n",
    "                    break\n",
    "        embedding_matrix[i]=embedding_vector\n",
    "    x_train.append(embedding_matrix)\n",
    "\n",
    "print(len(x_train))\n",
    "print(\"embedding done\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 128, 8, 250)\n",
      "(5000, 128, 8, 250)\n",
      "(25546, 128, 8, 250)\n",
      "60%\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train,dtype = 'float32')\n",
    "\n",
    "\n",
    "dev_x = x_train[:5000]\n",
    "dev_y = labels[:5000]\n",
    "\n",
    "test_x = x_train[5000:10000]\n",
    "test_y = labels[5000:10000]\n",
    "#到35546為止為label data\n",
    "train_x = x_train[10000:35546]\n",
    "\n",
    "train_y = labels[10000:]\n",
    "# !ls\n",
    "print(dev_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_x.shape)\n",
    "\n",
    "print(\"60%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意層\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = 50\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], 1)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "            \n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'attention_17/Variable:0' shape=(100, 1) dtype=float32> W\n",
      "tracking <tf.Variable 'attention_17/Variable_1:0' shape=(50,) dtype=float32> b\n",
      "tracking <tf.Variable 'attention_17/Variable_2:0' shape=(50, 1) dtype=float32> u\n",
      "tracking <tf.Variable 'attention_18/Variable:0' shape=(100, 1) dtype=float32> W\n",
      "tracking <tf.Variable 'attention_18/Variable_1:0' shape=(50,) dtype=float32> b\n",
      "tracking <tf.Variable 'attention_18/Variable_2:0' shape=(50, 1) dtype=float32> u\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 128, 8, 250)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 128, 100)          230900    \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 128, 200)          120600    \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 128, 100)          20100     \n",
      "_________________________________________________________________\n",
      "attention_18 (Attention)     (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 372,507\n",
      "Trainable params: 372,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model fitting - Hierachical attention network\n",
      "Train on 25546 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "25546/25546 [==============================] - 226s 9ms/step - loss: 0.8761 - acc: 0.7162 - val_loss: 0.8557 - val_acc: 0.7368\n",
      "Epoch 2/3\n",
      "25546/25546 [==============================] - 225s 9ms/step - loss: 0.5264 - acc: 0.8253 - val_loss: 0.8273 - val_acc: 0.7466\n",
      "Epoch 3/3\n",
      "23744/25546 [==========================>...] - ETA: 14s - loss: 0.4884 - acc: 0.8341"
     ]
    }
   ],
   "source": [
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(sentence_input)\n",
    "l_dense = TimeDistributed(Dense(100))(l_lstm)\n",
    "l_att = Attention()(l_dense)\n",
    "sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "l_dense_sent = TimeDistributed(Dense(100))(l_lstm_sent)\n",
    "l_att_sent = Attention()(l_dense_sent)\n",
    "preds = Dense(7, activation='softmax')(l_att_sent)\n",
    "model = Model(review_input, preds)\n",
    "adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, decay=0.01, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "filepath = \"./HAN3e_4.h5\"\n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.summary()\n",
    "print(\"model fitting - Hierachical attention network\")\n",
    "model.fit(train_x, train_y, validation_data=(dev_x,dev_y),epochs=3, batch_size=32,callbacks = callbacks_list)\n",
    "model.save_weights('HAN3e_4_decay0_para.h5') ##存參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sentence_input = Input(shape=(MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "# l_lstm = Bidirectional(GRU(300, return_sequences=True))(sentence_input)\n",
    "# l_att = AttLayer(300)(l_lstm)\n",
    "# sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "# review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "# review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "# # l_drop1 = Dropout(0.3)(review_encoder)\n",
    "# # l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "# dropout = Dropout(0.2)(review_encoder)\n",
    "# filter_sizes = [3,4,5]\n",
    "# convs = []\n",
    "# for filter_size in filter_sizes:\n",
    "#     conv = Conv1D(filters=64, kernel_size=filter_size, padding='same', activation='relu')(dropout)\n",
    "#     pool = MaxPooling1D(filter_size)(conv)\n",
    "#     convs.append(pool)\n",
    "        \n",
    "# concatenate = Concatenate(axis=1)(convs)\n",
    "# drop_out = Dropout(0.1)(concatenate)\n",
    "# l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(drop_out)\n",
    "# preds = Dense(7, activation='softmax')(l_lstm_sent)\n",
    "# l_att_sent = AttLayer(100)(preds)\n",
    "\n",
    "# model = Model(review_input, l_att_sent)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='Adam',\n",
    "#               metrics=['acc'])\n",
    "\n",
    "\n",
    "# filepath = \"best_HAHNN.h5\"\n",
    " \n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max', period=1)\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "# print(\"model fitting - Hierachical attention network\")\n",
    "# model.fit(test_x, test_y, validation_data=(dev_x,dev_y),epochs=3, batch_size=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(test_x,test_y,model):\n",
    "    test_y = np.array(test_y,dtype ='int64')\n",
    "    total = len(test_x)\n",
    "    logits=model.predict(test_x,batch_size=50)\n",
    "    pred=np.argmax(logits, axis=1)\n",
    "    correct=0 #對的有幾個\n",
    "    label_list = ['政治','生活','國際','體育','娛樂','社會','財經']\n",
    "    total_labels =[0,0,0,0,0,0,0]\n",
    "    correct_labels = [0,0,0,0,0,0,0]\n",
    "    total_labels = np.array(total_labels)\n",
    "    correct_labels = np.array(correct_labels)\n",
    "    for i in range(len(test_x)):\n",
    "        total_labels += test_y[i]\n",
    "        if test_y[i][pred[i]]==1.0:\n",
    "            correct = correct+1\n",
    "            correct_labels[pred[i]] += 1\n",
    "    for i in range(len(total_labels)):\n",
    "            print(label_list[i],':',correct_labels[i],'/',total_labels[i], 'Acc :', (correct_labels[i]/total_labels[i]))\n",
    "    print('Total：',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vote_acc(test_x,test_y,model,model2,model3):\n",
    "    test_y = np.array(test_y,dtype ='int64')\n",
    "    total = len(test_x)\n",
    "    logits=model.predict(test_x,batch_size=50)\n",
    "    logits2=model2.predict(test_x,batch_size=50)\n",
    "    logits3=model3.predict(test_x,batch_size=50)\n",
    "    pred=np.argmax(logits, axis=1)\n",
    "    pred2=np.argmax(logits2, axis=1)\n",
    "    pred3=np.argmax(logits3, axis=1)\n",
    "    correct=0 #對的有幾個\n",
    "    label_list = ['政治','生活','國際','體育','娛樂','社會','財經']\n",
    "    total_labels =[0,0,0,0,0,0,0]\n",
    "    correct_labels = [0,0,0,0,0,0,0]\n",
    "    total_labels = np.array(total_labels)\n",
    "    correct_labels = np.array(correct_labels)\n",
    "    for i in range(len(test_x)):\n",
    "        count = 0\n",
    "        total_labels += test_y[i]\n",
    "        if test_y[i][pred[i]]==1.0:\n",
    "            count+=1\n",
    "        if test_y[i][pred2[i]]==1.0:\n",
    "            count+=1\n",
    "        if test_y[i][pred3[i]]==1.0:\n",
    "            count+=1\n",
    "        if count>=2:\n",
    "            correct = correct+1\n",
    "            correct_labels[pred[i]] += 1\n",
    "    for i in range(len(total_labels)):\n",
    "            print(label_list[i],':',correct_labels[i],'/',total_labels[i], 'Acc :', (correct_labels[i]/total_labels[i]))\n",
    "    print('Total：',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 有bug\n",
    "def test_acc_two_ans(test_x,test_y,model):\n",
    "    test_y = np.array(test_y,dtype ='int64')\n",
    "    total = len(test_x)\n",
    "    logits=model.predict(test_x,batch_size=50)\n",
    "    pred=np.argmax(logits, axis=1)\n",
    "    for i in range(len(logits)):\n",
    "        logits[i][pred[i]] = 0.0\n",
    "    pred_sec = np.argmax(logits,axis=1)\n",
    "    correct=0 #對的有幾個\n",
    "    label_list = ['政治','生活','國際','體育','娛樂','社會','財經']\n",
    "    total_labels =[0,0,0,0,0,0,0]\n",
    "    correct_labels = [0,0,0,0,0,0,0]\n",
    "    total_labels = np.array(total_labels)\n",
    "    correct_labels = np.array(correct_labels)\n",
    "    for i in range(len(test_x)):\n",
    "        total_labels += test_y[i]\n",
    "        if test_y[i][pred[i]]==1.0 or test_y[i][pred_sec[i]]==1.0:\n",
    "            correct = correct+1\n",
    "            correct_labels+= test_y[i]\n",
    "    for i in range(len(total_labels)):\n",
    "            print(label_list[i],':',correct_labels[i],'/',total_labels[i], 'Acc :', (correct_labels[i]/total_labels[i]))\n",
    "    print('Total：',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Attention",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ab752e1ced98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HAN.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HAN1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    625\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1042\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         layer = deserialize_layer(config.pop('layer'),\n\u001b[0;32m--> 112\u001b[0;31m                                   custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1042\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: Attention"
     ]
    }
   ],
   "source": [
    "model2 = Model(review_input, preds)\n",
    "model2 = keras.models.load_model('HAN.h5')\n",
    "model3 = Model(review_input, preds)\n",
    "model3 = keras.models.load_model('HAN1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "政治 : 915 / 1104 Acc : 0.8288043478260869\n",
      "生活 : 1051 / 1107 Acc : 0.9494128274616079\n",
      "國際 : 394 / 424 Acc : 0.9292452830188679\n",
      "體育 : 359 / 359 Acc : 1.0\n",
      "娛樂 : 642 / 653 Acc : 0.9831546707503829\n",
      "社會 : 392 / 453 Acc : 0.8653421633554084\n",
      "財經 : 874 / 900 Acc : 0.9711111111111111\n",
      "Total： 0.9254\n",
      "政治 : 778 / 1104 Acc : 0.7047101449275363\n",
      "生活 : 906 / 1107 Acc : 0.8184281842818428\n",
      "國際 : 275 / 424 Acc : 0.6485849056603774\n",
      "體育 : 357 / 359 Acc : 0.9944289693593314\n",
      "娛樂 : 617 / 653 Acc : 0.9448698315467075\n",
      "社會 : 328 / 453 Acc : 0.7240618101545254\n",
      "財經 : 820 / 900 Acc : 0.9111111111111111\n",
      "Total： 0.8162\n"
     ]
    }
   ],
   "source": [
    "test_acc_two_ans(test_x,test_y,model)\n",
    "test_acc(test_x,test_y,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logits=model.predict(test_x,batch_size=50)\n",
    "pred=np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104\n",
      "0.8208\n"
     ]
    }
   ],
   "source": [
    "#驗證還沒加入unlabel data的表現\n",
    "correct=0 #對的有幾個\n",
    "for i in range(5000):\n",
    "    if test_y[i][pred[i]]==1.0:\n",
    "        correct = correct+1\n",
    "print(correct)\n",
    "acc=correct/5000\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##預測\n",
    "u_train = x_train[35546:]\n",
    "u_pred = model.predict(u_train,batch_size=50)\n",
    "ary =[] ##準備刪除的所有資料位置\n",
    "for i in range(u_train.shape[0]):\n",
    "    ans = u_pred[i][0]\n",
    "    for j in range(7):\n",
    "        if u_pred[i][j]>ans:\n",
    "            ans=u_pred[i][j]\n",
    "    if ans<acc: ##比模型準確率高\n",
    "        ary.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3992579e-01 2.1731112e-02 8.2282134e-04 7.1054637e-01 4.6229051e-04\n",
      " 2.6327234e-02 1.8443231e-04]\n",
      "(10691, 7)\n",
      "[8.8439238e-01 5.6384900e-04 5.2494352e-06 9.5021096e-06 1.8242728e-06\n",
      " 1.1501102e-01 1.6204893e-05]\n",
      "(6374, 7)\n"
     ]
    }
   ],
   "source": [
    "print(u_pred[3])\n",
    "print(u_pred.shape)\n",
    "u_pred=np.delete(u_pred,ary,axis=0) ##刪除所有資料不夠好的位置\n",
    "print(u_pred[3])\n",
    "print(u_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 44.9 GiB for an array with shape (39218, 64, 8, 300) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a76b29b958a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mary_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m35546\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mary_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mu_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4415\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4416\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4417\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 44.9 GiB for an array with shape (39218, 64, 8, 300) and data type float64"
     ]
    }
   ],
   "source": [
    "ary_label = []##刪除x_train用ㄉ\n",
    "\n",
    "for i in range(len(ary)):\n",
    "    ary_label.append(ary[i]+35546)\n",
    "x_train = np.delete(x_train,ary_label,axis=0)\n",
    "print(x_train.shape)\n",
    "u_pred = np.argmax(u_pred, axis=1)\n",
    "##轉one-hot\n",
    "u_pred = np.array(u_pred)\n",
    "u_pred = np_utils.to_categorical(u_pred)\n",
    "print(u_pred.shape)\n",
    "print(u_pred[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred = np.argmax(u_pred, axis=1)\n",
    "##轉one-hot\n",
    "u_pred = np.array(u_pred)\n",
    "u_pred = np_utils.to_categorical(u_pred)\n",
    "print(u_pred.shape)\n",
    "print(u_pred[7])\n",
    "train_y=labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#串起來\n",
    "train_y=np.concatenate((train_y,u_pred),axis=0)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再train一個model\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "l_lstm = Bidirectional(GRU(100, return_sequences=True))(sentence_input)\n",
    "dropout = Dropout(0.2)(l_lstm)\n",
    "filter_sizes = [3,4,5]\n",
    "convs = []\n",
    "for filter_size in filter_sizes:\n",
    "    conv = Conv1D(filters=64, kernel_size=filter_size, padding='same', activation='relu')(dropout)\n",
    "    pool = MaxPooling1D(filter_size)(conv)\n",
    "    convs.append(pool)\n",
    "        \n",
    "concatenate = Concatenate(axis=1)(convs)\n",
    "drop_out = Dropout(0.1)(concatenate)\n",
    "l_att = AttLayer(100)(drop_out)\n",
    "sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH,EMBEDDING_DIM), dtype='float32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "# l_drop1 = Dropout(0.3)(review_encoder)\n",
    "l_lstm_sent = Bidirectional(GRU(100, return_sequences=True))(review_encoder)\n",
    "l_att_sent = AttLayer(100)(l_lstm_sent)\n",
    "preds = Dense(7, activation='softmax')(l_att_sent)\n",
    "u_model = Model(review_input, preds)\n",
    "\n",
    "u_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "filepath = \"best_HAN_with_unlabel.h5\"\n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "train_x=x_train[10000:]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "u_model.summary()\n",
    "print(\"model fitting - Hierachical attention network\")\n",
    "u_model.fit(train_x, train_y, validation_data=(dev_x,dev_y),epochs=3, batch_size=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "pred=u_model.predict(test_x,batch_size=50)\n",
    "pred=np.argmax(pred, axis=1)\n",
    "print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4176\n",
      "0.8352\n"
     ]
    }
   ],
   "source": [
    "#加入unlabel data後的表現\n",
    "correct=0 #對的有幾個\n",
    "for i in range(5000):\n",
    "    if test_y[i][pred[i]]==1.0:\n",
    "        correct = correct+1\n",
    "print(correct)\n",
    "acc=correct/5000\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
