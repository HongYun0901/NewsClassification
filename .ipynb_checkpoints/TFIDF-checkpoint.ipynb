{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35546, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['type','title','text']\n",
    "df = pd.read_csv('./all_after_mapping.tsv',sep='\\t',names=column_names)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenlizeword = np.load('tokenlizeword0225_nopunct.npy',allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['type'].values\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "264.60656613965006\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35546,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(tokenlizeword[0]))\n",
    "count = 0\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "    tokenlizeword[k] = np.array(tokenlizeword[k])\n",
    "    count+=tokenlizeword[k].shape[0]\n",
    "print(count/tokenlizeword.shape[0])\n",
    "print(type(tokenlizeword[0]))\n",
    "li = []\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "    li.append(' '.join(tokenlizeword[k]))\n",
    "li = np.array(li)\n",
    "li.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '11', '11月', '12', '12月', '13', '14', '15', '16', '17', '18', '1月', '20', '2018年', '2019年', '2020', '2020年', '2月', '30', '3月', '50', '一定', '一樣', '一直', '一起', '上午', '下午', '不僅', '不同', '不少', '不斷', '不會', '不能', '不要', '不過', '世界', '中國', '中央', '中心', '主席', '主要', '之後', '事件', '事情', '交易', '交通', '人員', '人士', '人數', '人民', '什麼', '今天', '今年', '今日', '今晚', '他們', '代表', '以上', '以來', '以及', '任何', '企業', '但是', '作為', '使用', '來自', '保護', '個人', '候選人', '健康', '傳出', '價格', '入境', '內容', '全球', '兩岸', '公共', '公司', '公告', '公園', '公布', '公里', '公開', '共同', '其中', '其他', '其實', '再度', '冠狀', '出席', '出現', '分享', '分別', '分區', '分鐘', '利用', '到場', '前往', '副總統', '力量', '加上', '加入', '加強', '努力', '包含', '包括', '區域', '協助', '協會', '協議', '南韓', '原因', '原本', '去年', '參加', '參與', '取得', '取消', '受到', '口罩', '另外', '只是', '只有', '只要', '召開', '可以', '可能', '台中', '台中市', '台北', '台北市', '台南', '台商', '台灣', '合作', '同時', '吸引', '呼籲', '員工', '問題', '單位', '嚴重', '回應', '因應', '因此', '因為', '國內', '國家', '國會', '國民黨', '國際', '團隊', '地區', '地方', '執行', '報告', '報導', '增加', '外界', '大學', '大家', '大選', '大陸', '女兒', '如何', '如果', '委員會', '媒體', '孩子', '學校', '學生', '安全', '安排', '完全', '完成', '宣布', '家人', '家庭', '專家', '專業', '對手', '對方', '對於', '導致', '小時', '展開', '川普', '工作', '工程', '已經', '市場', '市府', '市民', '市長', '希望', '幫助', '平台', '年輕人', '建設', '建議', '引發', '引起', '強調', '影片', '影響', '很多', '必須', '患者', '情況', '意外', '感染', '感謝', '應該', '成功', '成為', '成立', '成長', '我們', '所以', '所有', '手機', '批評', '技術', '投票', '投資', '拿下', '持續', '指出', '指揮', '指數', '掌握', '接受', '推出', '推動', '措施', '提供', '提出', '提到', '提升', '提醒', '擔任', '擔心', '擴大', '支持', '改善', '政府', '政治', '政策', '政黨', '教育', '數據', '文化', '新北市', '新型', '新聞', '方式', '方面', '旅客', '旅遊', '日前', '日本', '明天', '明年', '春節', '昨天', '昨日', '是否', '時代', '時候', '時間', '晚間', '更多', '最後', '會議', '朋友', '服務', '期待', '期間', '未來', '柯文哲', '根據', '桃園', '業者', '機場', '機會', '機構', '檢疫', '正在', '正式', '此外', '武漢', '歷史', '死亡', '比賽', '比較', '民主', '民眾', '民進黨', '決定', '沒想到', '沒有', '治療', '注意', '活動', '消息', '減少', '準備', '演出', '澳洲', '為了', '無法', '照片', '照顧', '營運', '爆發', '爭取', '特別', '狀況', '獲得', '現在', '現場', '球員', '球隊', '環境', '甚至', '生活', '生產', '產品', '產業', '由於', '申請', '男子', '留言', '當地', '當時', '當選', '疑似', '疫情', '病例', '病毒', '症狀', '發展', '發文', '發現', '發生', '發表', '目前', '目標', '直接', '相信', '相當', '相關', '看到', '真的', '知道', '研究', '確定', '確診', '社區', '社會', '科技', '積極', '穩定', '空氣', '空間', '立委', '立法院', '競選', '第1', '第2', '第一', '第一手', '第三', '第二', '管理', '節目', '籃板', '粉絲', '系統', '紀錄', '紛紛', '組織', '結束', '結果', '經濟', '經過', '綜合', '維持', '網友', '網路', '緊急', '總統', '總部', '繼續', '美元', '美國', '而且', '聯盟', '肺炎', '能力', '能夠', '臉書', '自己', '自由', '至於', '舉行', '舉辦', '航空', '英國', '董事長', '蔡英文', '處理', '行動', '行為', '衛生', '表現', '表示', '表達', '補助', '要求', '規劃', '規定', '覺得', '觀光', '解決', '計畫', '訊息', '討論', '記者', '記者會', '設計', '許多', '認為', '說明', '調整', '調查', '警方', '議員', '貿易', '資料', '資訊', '質疑', '賴清德', '購買', '超過', '身體', '辦理', '近日', '近期', '透過', '透露', '這些', '這樣', '通報', '通過', '造成', '連任', '連續', '進一步', '進入', '進行', '遊客', '遊行', '運動', '過去', '過年', '過程', '違反', '選區', '選擇', '選民', '選舉', '避免', '邀請', '還是', '部分', '鄉親', '配合', '醫師', '醫療', '醫院', '重要', '針對', '銀行', '長期', '開始', '開放', '關係', '關注', '防疫', '除了', '陸續', '階段', '隔離', '集團', '雖然', '雙方', '需求', '需要', '非常', '面對', '韓國', '韓國瑜', '順利', '預期', '預計', '顯示', '風險', '首次', '香港', '高雄', '高雄市']\n",
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
      "(35546, 512)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=512)\n",
    "X = vectorizer.fit_transform(li)\n",
    "word = vectorizer.get_feature_names()\n",
    "print(word)\n",
    "print(X.toarray())\n",
    " \n",
    "transformer = TfidfTransformer()\n",
    "print(transformer)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "x = tfidf.toarray()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35546, 512)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "dev_x = x[:5000]\n",
    "dev_y = labels[:5000]\n",
    "\n",
    "test_x = x[5000:10000]\n",
    "test_y = labels[5000:10000]\n",
    "\n",
    "train_x = x[10000:]\n",
    "train_y = labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class TFIDFdataset(Dataset):\n",
    "    def __init__(self, x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "trainset = TFIDFdataset(train_x,train_y)\n",
    "trainloader = DataLoader(trainset,batch_size=BATCH_SIZE,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "input_dim  = x.shape[1]\n",
    "class TFIDFmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TFIDFmodel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "Epoch: 0001 cost = 1.918476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type TFIDFmodel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 cost = 1.891571\n",
      "Epoch: 0003 cost = 1.815583\n",
      "Epoch: 0004 cost = 1.711460\n",
      "Epoch: 0005 cost = 1.574211\n"
     ]
    }
   ],
   "source": [
    "model = TFIDFmodel()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print('device:',device)\n",
    "model = model.float()\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0\n",
    "    for data in trainloader:\n",
    "        x,y = [t.to(device) for t in data]\n",
    "        x = x.float()\n",
    "        y = y.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        y = y.long()\n",
    "        loss = criterion(output, y)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "    torch.save(model, 'model_TFIDF_512.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = TFIDFdataset(test_x,test_y)\n",
    "testloader = DataLoader(testset,batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                x,y = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "            outputs  = model(x)\n",
    "\n",
    "            after_softmax = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                total += y.shape[0]\n",
    "                correct += (pred == y).sum().item()\n",
    "\n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions , predictions_withoutmax, acc\n",
    "    return predictions_withoutmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0764, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6ad43ef452b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpred_probi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "pred , pred_probi ,acc = get_predictions(model,testloader,True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
