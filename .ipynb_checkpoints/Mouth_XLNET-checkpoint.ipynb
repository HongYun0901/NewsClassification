{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from transformers import XLNetTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['type','title','text']\n",
    "train = pd.read_csv('./data_after_sep/train.tsv',sep='\\t',names=column)\n",
    "test =pd.read_csv('./data_after_sep/dev.tsv',sep='\\t',names=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25546,)\n",
      "(25546,)\n"
     ]
    }
   ],
   "source": [
    "train_x = train['text']\n",
    "train_y = train['type']\n",
    "train_x = np.array(train_x.tolist())\n",
    "train_y = np.array(train_y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "test_x = test['text']\n",
    "test_y = test['type']\n",
    "test_x = np.array(test_x.tolist())\n",
    "test_y = np.array(test_y)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 512\n",
    "NUM_LABELS = 7\n",
    "tokenizer = XLNetTokenizer.from_pretrained('./chinese_xlnet_mid_pytorch/')\n",
    "input_dict = tokenizer.batch_encode_plus(train_x,\n",
    "                                         add_special_tokens = True,\n",
    "                                         max_length = MAX_LENGTH,\n",
    "                                         return_special_tokens_mask = True,\n",
    "                                         pad_to_max_length = True,\n",
    "                                         return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,input_dict,y):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        y = self.y[idx]\n",
    "        return inputid , tokentype , attentionmask , y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, input_dict):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "       \n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        return inputid , tokentype , attentionmask \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "trainset = TrainDataset(input_dict,train_y)\n",
    "trainloader = DataLoader(trainset,batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "test_dict = tokenizer.batch_encode_plus(test_x,\n",
    "                                         add_special_tokens = True,\n",
    "                                         max_length = MAX_LENGTH,\n",
    "                                         return_special_tokens_mask = True,\n",
    "                                         pad_to_max_length = True,\n",
    "                                         return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "testset = TrainDataset(test_dict,test_y)\n",
    "testloader = DataLoader(testset,batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./chinese_xlnet_mid_pytorch/ were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at ./chinese_xlnet_mid_pytorch/ and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetForSequenceClassification\n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained('./chinese_xlnet_mid_pytorch/',num_labels = NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            tokens, segments, masks = data[:3]\n",
    "            outputs = model(input_ids=tokens, \n",
    "                            token_type_ids=segments, \n",
    "                            attention_mask=masks)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            after_softmax = F.softmax(logits.data, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "            \n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-3e2e8f857425>\", line 30, in <module>\n",
      "    optimizer.step()\n",
      "  File \"/home/nlp/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 15, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/nlp/.local/lib/python3.6/site-packages/torch/optim/adam.py\", line 100, in step\n",
      "    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 47, in <module>\n",
      "    from tensorflow.contrib import distributions\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 29, in <module>\n",
      "    from tensorflow.contrib.distributions.python.ops import bijectors\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 44, in <module>\n",
      "    from tensorflow.contrib.distributions.python.ops.estimator import *\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/python/ops/estimator.py\", line 21, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/__init__.py\", line 93, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn import *\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/__init__.py\", line 28, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn import *\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/__init__.py\", line 30, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn import estimators\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/__init__.py\", line 302, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py\", line 34, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 36, in <module>\n",
      "    from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 393, in <module>\n",
      "    ['tags', 'transforms'])\n",
      "  File \"/usr/lib/python3.6/collections/__init__.py\", line 429, in namedtuple\n",
      "    exec(class_definition, namespace)\n",
      "  File \"<string>\", line 5, in <module>\n",
      "  File \"<string>\", line 45, in GraphRewriteSpec\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    step = 0\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data in trainloader:\n",
    "        tokens_tensors, segments_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors, \n",
    "                            labels=labels)\n",
    "        loss = outputs[0]\n",
    "        pred = outputs[1]\n",
    "        total += pred.size()[0]\n",
    "        pred = torch.argmax(pred,dim=-1)\n",
    "        correct += (pred==labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    torch.save(model.state_dict(),'./xlnet_state_dict'+str(epoch)+'.pkl')\n",
    "    prediction, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "    test_pred,test_acc = get_predictions(model, testloader, compute_acc=True)\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "testset = TrainDataset(test_dict,test_y)\n",
    "testloader = DataLoader(testset,batch_size = BATCH_SIZE)\n",
    "NUM_LABELS = 7\n",
    "from transformers import XLNetForSequenceClassification\n",
    "\n",
    "model = XLNetForSequenceClassification.from_pretrained('./chinese_xlnet_mid_pytorch/',num_labels = NUM_LABELS)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./xlnet_state_dict2.pkl'))\n",
    "model.eval()\n",
    "test_pred,test_acc = get_predictions(model, testloader, compute_acc=True)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
