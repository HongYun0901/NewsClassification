{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification\n",
    "import torch.nn as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW \n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "test = pd.read_csv('./sample_submission.csv')\n",
    "model_path = './roberta/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.read_csv('./documents.csv')\n",
    "doc_list = doc['doc_id'].tolist()\n",
    "doc_text = doc['doc_text'].tolist()\n",
    "doc_dict = {doc_list[i]: i for i in range(len(doc_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/.local/lib/python3.7/site-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_q = pd.read_csv('./train_queries.csv')\n",
    "train_query_data = [t.lower() for t in train_q['query_text']]\n",
    "train_top_1000 = [t.split() for t in train_q['bm25_top1000']]\n",
    "train_pos_list = [t.split() for t in train_q['pos_doc_ids']]\n",
    "train_neg_list = [t[:] for t in train_top_1000] ##後800篇\n",
    "train_pos_list = np.array(train_pos_list)\n",
    "train_top_1000 = np.array(train_top_1000)\n",
    "train_neg_list = np.array(train_neg_list) ##後970篇\n",
    "print(train_neg_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 裡面現在存的是pos doc idx\n",
    "for pos_docs in range(train_pos_list.shape[0]):\n",
    "    for idx in range(len(train_pos_list[pos_docs])):\n",
    "        train_pos_list[pos_docs][idx] = doc_dict[train_pos_list[pos_docs][idx]]\n",
    "        \n",
    "for pos_docs in range(train_top_1000.shape[0]):\n",
    "    for idx in range(len(train_top_1000[pos_docs])):\n",
    "        train_top_1000[pos_docs][idx] = doc_dict[train_top_1000[pos_docs][idx]]\n",
    "        \n",
    "for pos_docs in range(train_neg_list.shape[0]):\n",
    "    for idx in range(len(train_neg_list[pos_docs])):\n",
    "        train_neg_list[pos_docs][idx] = doc_dict[train_neg_list[pos_docs][idx]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(content):\n",
    "    content = content.replace('\\n','.').replace('\\t',',')# erease white space cause English name error\n",
    "    content = re.sub(\"[+\\.\\/_,$%●▼►^*(+\\\"\\']+|[+——~@#￥%……&*（）★]\", \"\",content)\n",
    "    return content.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, input_dict, y):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "#         self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "    def __getitem__(self, idx):\n",
    "        input_id = self.input_ids[idx]\n",
    "#         tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        y = self.y[idx]\n",
    "        return input_id, attentionmask, y\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question = []\n",
    "train_choice = []\n",
    "train_y = []\n",
    "N = 3 ## 錯的文章數量\n",
    "for i in range(len(train_query_data)):\n",
    "    for j in range(len(train_pos_list[i])):\n",
    "        if type(doc_text[train_pos_list[i][j]]) != float:\n",
    "            train_y.append(1)\n",
    "            train_question.append(train_query_data[i])\n",
    "            train_choice.append(clean_string(doc_text[train_pos_list[i][j]]))\n",
    "            l = random.sample(range(0,999), N)\n",
    "            count = -1\n",
    "            while(count<N): ##有抽到前1000的\n",
    "                if count != -1:\n",
    "                    l = random.sample(range(0,999), N)\n",
    "                count = 0 \n",
    "                for check in l:\n",
    "                    if check not in train_pos_list[i] and type(doc_text[int(train_neg_list[i][check])]) != float: ##不是POS\n",
    "                        count += 1        \n",
    "            for idx in l:\n",
    "                train_y.append(0)\n",
    "                train_question.append(train_query_data[i])\n",
    "                train_choice.append(clean_string(doc_text[int(train_neg_list[i][idx])]))\n",
    "# train_question = np.array(train_question)\n",
    "# train_choice = np.array(train_choice)\n",
    "# train_question = json.dumps(train_question)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = 6000\n",
    "test_q_set = train_question[:EVAL]\n",
    "test_c_set = train_choice[:EVAL]\n",
    "train_q_set = train_question[EVAL:]\n",
    "train_c_set = train_choice[EVAL:]\n",
    "\n",
    "test_y_set = train_y[:EVAL]\n",
    "train_y_set = train_y[EVAL:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d648d6d0dc784b4e9a845db6647dcc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898823.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542c1fc7cd2046bba5bbee012372de75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./roberta/ were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./roberta/ and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## model 各參數\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 2\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path,num_labels = num_labels)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "EVAL = 6000\n",
    "EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(),lr = 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_test_acc(model, testloader):\n",
    "    model.eval()  ##test mode\n",
    "    total = 0 ##total_num\n",
    "    correct = 0 ##correct_num\n",
    "    with torch.no_grad():   ##eval不計算gradient \n",
    "        for data in testloader:\n",
    "            tokens_tensors , masks_tensors,labels = [t.to(device) for t in data]\n",
    "            outputs = model(input_ids = tokens_tensors,\n",
    "                           attention_mask = masks_tensors,\n",
    "                           labels = labels)\n",
    "            pred = torch.argmax(outputs[1],dim=-1)\n",
    "            total += labels.size()[0]\n",
    "            correct += (pred == labels).sum().item()\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_test_score(model, testloader):\n",
    "    model.eval()  ##test mode\n",
    "    total = 0 ##total_num\n",
    "    result_batch = [] ## all label 1's score\n",
    "    correct = 0 ##correct_num\n",
    "    with torch.no_grad():   ##eval不計算gradient \n",
    "        for data in testloader:\n",
    "            tokens_tensors ,masks_tensors,labels = [t.to(device) for t in data]\n",
    "            outputs = model(input_ids = tokens_tensors,\n",
    "                           attention_mask = masks_tensors,\n",
    "                           labels = labels)\n",
    "            score = outputs[1]\n",
    "            for idx in range(score.shape[0]):\n",
    "                result_batch.append(score[idx][1])\n",
    "#             result_score = 0\n",
    "#             for num in score:\n",
    "#                 for result in num:\n",
    "#                     result_score += result\n",
    "#             print(result_score)\n",
    "    return result_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "train_input_dict = tokenizer(train_q_set, train_c_set, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors=\"pt\",\n",
    "                             max_length = 512)\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "trainset = TrainDataset(train_input_dict, train_y_set) ##trainset參數如init\n",
    "trainloader = DataLoader(trainset, batch_size = TRAIN_BATCH_SIZE, shuffle = True)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test \n",
    "test_input_dict = tokenizer(test_q_set, test_c_set, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors=\"pt\",\n",
    "                             max_length = 512)\n",
    "TEST_BATCH_SIZE = 64\n",
    "testset = TrainDataset(test_input_dict, test_y_set) ##trainset參數如init\n",
    "testloader = DataLoader(testset, batch_size = TEST_BATCH_SIZE, shuffle = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] 7845/7846 Loss: 4456.6424 Acc : 0.7499   test acc: 0.75\n",
      "Epoch [2/3] 3036/7846 Loss: 1725.7231 Acc : 0.7466"
     ]
    }
   ],
   "source": [
    "# e = 0.1 ##label smooth的參數\n",
    "# smooth_loss_fnc = F.CrossEntropyLoss()\n",
    "for epoch in range(EPOCHS):\n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for (i,data) in enumerate(trainloader):\n",
    "        \n",
    "        tokens_tensors ,   masks_tensors , labels  = [t.to(device) for t in data]\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                             attention_mask=masks_tensors,\n",
    "                             labels = labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = outputs[1]\n",
    "#         max_idx = torch.argmax(logits,dim = -1)\n",
    "#         for count in range(labels.size()[0]):\n",
    "#             for idx in range(len(logits[count])):\n",
    "#                 if(idx == max_idx[count]):\n",
    "#                     logits[count][idx] *= 1/(1-e)\n",
    "#                 else:\n",
    "#                     logits[count][idx] -= e/(num_labels-1)\n",
    "#         for count in range(labels.size()[0]):\n",
    "#             print(count)\n",
    "#             for idx in range(len(logits[count])):\n",
    "#                 print(idx)\n",
    "#                 logits[count][idx] += e/(num_labels-1)\n",
    "#         smooth_loss = smooth_loss_fnc(logits,labels)\n",
    "        pred = torch.argmax(logits,dim = -1)\n",
    "        loss = outputs[0]\n",
    "#         loss += smooth_loss\n",
    "#         loss = bert_outputs[0]*0.5 +weight_loss*0.5\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += pred.size()[0]\n",
    "        correct += (pred == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        print(f'\\rEpoch [{epoch+1}/{EPOCHS}] {i}/{len(trainloader)} Loss: {running_loss:.4f} Acc : {(correct/total):.4f}', end='')\n",
    "    test_acc = get_test_acc(model,testloader)\n",
    "    ##all save\n",
    "    torch.save(model.state_dict(),'./HW6_model/HW6_roberta_baseline_' + str(epoch) + '.pkl')\n",
    "    print('   test acc:' , test_acc)\n",
    "    with open('./hw6_roberta_test_score'+str(epoch)+'.txt','w') as f:\n",
    "        f.write(str(test_acc))\n",
    "        f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q = pd.read_csv('./test_queries.csv')\n",
    "test_query_list = test_q['query_id'].tolist()\n",
    "test_query_data = [t.lower() for t in test_q['query_text']]\n",
    "rerank_idx_list = [t.split() for t in test_q['bm25_top1000']]\n",
    "rerank_score_list = [t.split() for t in test_q['bm25_top1000_scores']]\n",
    "result_score_list = []\n",
    "print(test_query_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_score_list = np.zeros([80,1000]) ##分數\n",
    "for i in range(len(rerank_score_list)):\n",
    "    for j in range(len(rerank_score_list[0])):\n",
    "        result_score_list[i][j] = float(rerank_score_list[i][j])\n",
    "after_add_list = np.zeros([80,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ans_list = []\n",
    "for i in range(80):\n",
    "    print(i)\n",
    "    ans_list = []\n",
    "    idx_list = rerank_idx_list[i]\n",
    "    score_list = result_score_list[i].copy()\n",
    "    input_q = []\n",
    "    input_c = []\n",
    "    no_content_list = []\n",
    "    for j in range(len(idx_list)):\n",
    "        find = doc_dict[idx_list[j]] ## idx \n",
    "        if type(doc_text[find]) != float:\n",
    "            text = clean_string(doc_text[find])\n",
    "            input_q.append(test_query_data[i])\n",
    "            input_c.append(text)\n",
    "        else:\n",
    "            no_content_list.append(j) ##空的\n",
    "    batch_test_input_dict = tokenizer(input_q, input_c, \n",
    "                            padding=True, \n",
    "                            truncation=True, \n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length = 512)\n",
    "    TEST_BATCH_SIZE = 64\n",
    "    batch_testset = TrainDataset(batch_test_input_dict,torch.zeros([len(idx_list)], dtype=torch.long)) ##trainset參數如init 給label沒差\n",
    "    batch_testloader = DataLoader(batch_testset, batch_size = TEST_BATCH_SIZE, shuffle = False)  \n",
    "    score = get_test_score(model,batch_testloader)\n",
    "    no_content_count = 0\n",
    "    for k in range(len(score)):\n",
    "#         print(k)\n",
    "#         print(score[k])\n",
    "        if k not in no_content_list:\n",
    "            score_list[k+no_content_count] +=  7 * score[k]\n",
    "        else:\n",
    "            no_content_count += 1\n",
    "    after_add_list[i] = score_list\n",
    "    ans_idx_list = sorted(range(1000),reverse = True,key = lambda k : score_list[k])\n",
    "    for j in range(1000):\n",
    "        ans_list.append(rerank_idx_list[i][ans_idx_list[j]])\n",
    "    all_ans_list.append(ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hw6_result_BM25_roberta_baseline.txt','w') as f:\n",
    "    f.write('query_id,ranked_doc_ids\\n')\n",
    "    for i in range(80): \n",
    "        f.write(str(test_query_list[i]))\n",
    "        f.write(',')\n",
    "        for j in range(len(all_ans_list[0])):\n",
    "            f.write(all_ans_list[i][j])\n",
    "            f.write(' ')\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
