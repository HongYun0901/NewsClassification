{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['type','title','text']\n",
    "unlabel_df = pd.read_csv('./udn_for_mct.tsv',sep='\\t',names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_data = unlabel_df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['type','title','text']\n",
    "df = pd.read_csv('./all_after_mapping.tsv',sep='\\t',names=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenlizeword = np.load('tokenlizeword0225_nopunct.npy',allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmodel = Word2Vec(tokenlizeword, size=300, window=5, min_count=0)\n",
    "wmodel.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "labels = df['type'].values\n",
    "print(type(labels))\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "max_size = 512\n",
    "x_lstm = []\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "  # every article have max_size * 300 embedding matrix\n",
    "    embedding_matrix = np.zeros((max_size,300))\n",
    "    for i in range(len(tokenlizeword[k])):\n",
    "        if(i>=max_size):\n",
    "            break\n",
    "        embedding_matrix[i] = wmodel[tokenlizeword[k][i]]\n",
    "    x_lstm.append(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm = np.array(x_lstm,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_x = x_lstm[10000:]\n",
    "lstm_train_y = labels[10000:]\n",
    "\n",
    "lstm_test_x = x_lstm[5000:10000]\n",
    "test_y = labels[5000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "n_hidden = 128 # number of hidden units in one cell\n",
    "num_classes = 7  \n",
    "BATCH_SIZE = 8\n",
    "epochs = 20\n",
    "class BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTM_Attention, self).__init__()\n",
    "\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, n_hidden, bidirectional=True)\n",
    "        self.out = nn.Linear(n_hidden * 2, num_classes)\n",
    "\n",
    "    # lstm_output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        hidden = final_state.view(-1, n_hidden * 2, 1)   # hidden : [batch_size, n_hidden * num_directions(=2), 1(=n_layer)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2) # attn_weights : [batch_size, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        # [batch_size, n_hidden * num_directions(=2), n_step] * [batch_size, n_step, 1] = [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "#         return context, soft_attn_weights.data.numpy() # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "        return context, soft_attn_weights # context : [batch_size, n_hidden * num_directions(=2)]\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "#         input = self.embedding(X) # input : [batch_size, len_seq, embedding_dim]\n",
    "        input = X\n",
    "        input = input.permute(1, 0, 2) # input : [len_seq, batch_size, embedding_dim]\n",
    "#         print(input)\n",
    "        \n",
    "        hidden_state = Variable(torch.zeros(1*2, BATCH_SIZE, n_hidden)) # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        cell_state = Variable(torch.zeros(1*2, BATCH_SIZE, n_hidden)) # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        hidden_state = hidden_state.double()\n",
    "        cell_state = cell_state.double()\n",
    "        hidden_state = hidden_state.to(device)\n",
    "        cell_state = cell_state.to(device)\n",
    "#         print(cell_state)\n",
    "#         print(hidden_state)\n",
    "#         print(hidden_state)\n",
    "        # final_hidden_state, final_cell_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (hidden_state, cell_state))\n",
    "        output = output.permute(1, 0, 2) # output : [batch_size, len_seq, n_hidden]\n",
    "        attn_output, attention = self.attention_net(output, final_hidden_state)\n",
    "#         print('attn_output.shape',attn_output.shape)\n",
    "#         print('attention.shape',attention.shape)\n",
    "        return self.out(attn_output), attention # model : [batch_size, num_classes], attention : [batch_size, n_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lstmdataset(Dataset):\n",
    "    def __init__(self, x,y):\n",
    "        self.x = torch.from_numpy(x)\n",
    "#         self.x = torch.DoubleTensor(x)\n",
    "#         self.x = self.x.double()\n",
    "        self.y = torch.from_numpy(y)\n",
    "#         self.y = torch.DoubleTensor(y)\n",
    "#         self.y = self.y.double()\n",
    "#         print(type(self.x))\n",
    "#         print(type(self.y))\n",
    "\n",
    "        self.len = x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "#         print(index)\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "#         print(type(x))\n",
    "#         print(type(y))\n",
    "        return x , y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "lstm_trainset = Lstmdataset(lstm_train_x,lstm_train_y)\n",
    "lstm_trainloader = DataLoader(lstm_trainset,batch_size=BATCH_SIZE,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "264.60656613965006\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenlizeword[0]))\n",
    "count = 0\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "    tokenlizeword[k] = np.array(tokenlizeword[k])\n",
    "    count+=tokenlizeword[k].shape[0]\n",
    "print(count/tokenlizeword.shape[0])\n",
    "print(type(tokenlizeword[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35546,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "    li.append(' '.join(tokenlizeword[k]))\n",
    "li = np.array(li)\n",
    "li.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
      "(35546, 512)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=512)\n",
    "X = vectorizer.fit_transform(li)\n",
    "word = vectorizer.get_feature_names()\n",
    "# print(word)\n",
    "# print(X.toarray())\n",
    "transformer = TfidfTransformer()\n",
    "print(transformer)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "x = tfidf.toarray()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_x = x[5000:10000]\n",
    "tfidf_train_x = x[10000:]\n",
    "tfidf_train_y = labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_train_x shape: (25546, 512)\n",
      "tfidf_train_y shape: (25546,)\n",
      "tfidf_test_x shape: (5000, 512)\n",
      "test_y shape: (5000,)\n",
      "lstm_train_x shape: (25546, 512, 300)\n",
      "lstm_train_y shape: (25546,)\n",
      "lstm_test_x shape: (5000, 512, 300)\n",
      "test_y shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "print('tfidf_train_x shape:',tfidf_train_x.shape)\n",
    "print('tfidf_train_y shape:',tfidf_train_y.shape)\n",
    "print('tfidf_test_x shape:',tfidf_test_x.shape)\n",
    "print('test_y shape:',test_y.shape)\n",
    "print('lstm_train_x shape:',lstm_train_x.shape)\n",
    "print('lstm_train_y shape:',lstm_train_y.shape)\n",
    "print('lstm_test_x shape:',lstm_test_x.shape)\n",
    "print('test_y shape:',test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFdataset(Dataset):\n",
    "    def __init__(self, x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "input_dim  = x.shape[1]\n",
    "class TFIDFmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TFIDFmodel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_token = np.load('tokenlizeword0226_udn_for_mct.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmodel_unlabel = Word2Vec(unlabel_token ,size=300, window=5, min_count=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10691, 512, 300)\n"
     ]
    }
   ],
   "source": [
    "max_size = 512\n",
    "unlabel_for_lstm = []\n",
    "for k in range(unlabel_token.shape[0]):\n",
    "  # every article have max_size * 300 embedding matrix\n",
    "    embedding_matrix = np.zeros((max_size,300))\n",
    "    for i in range(len(unlabel_token[k])):\n",
    "        if(i>=max_size):\n",
    "            break\n",
    "        embedding_matrix[i] = wmodel_unlabel[unlabel_token[k][i]]\n",
    "    unlabel_for_lstm.append(embedding_matrix)\n",
    "unlabel_for_lstm = np.array(unlabel_for_lstm,dtype='float32')\n",
    "print(unlabel_for_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "380.2110186137873\n",
      "<class 'numpy.ndarray'>\n",
      "(10691,)\n",
      "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
      "(10691, 512)\n"
     ]
    }
   ],
   "source": [
    "print(type(unlabel_token[0]))\n",
    "count = 0\n",
    "for k in range(unlabel_token.shape[0]):\n",
    "    unlabel_token[k] = np.array(unlabel_token[k])\n",
    "    count+=unlabel_token[k].shape[0]\n",
    "print(count/unlabel_token.shape[0])\n",
    "print(type(unlabel_token[0]))\n",
    "li = []\n",
    "for k in range(unlabel_token.shape[0]):\n",
    "    li.append(' '.join(unlabel_token[k]))\n",
    "li = np.array(li)\n",
    "print(li.shape)\n",
    "vectorizer = CountVectorizer(max_features=512)\n",
    "X = vectorizer.fit_transform(li)\n",
    "word = vectorizer.get_feature_names()\n",
    "# print(word)\n",
    "# print(X.toarray())\n",
    "transformer = TfidfTransformer()\n",
    "print(transformer)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "unlabel_for_tfidf = tfidf.toarray()\n",
    "print(unlabel_for_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(dataloader):\n",
    "    lstm_model = BiLSTM_Attention()\n",
    "    lstm_model = lstm_model.double()\n",
    "    lstm_model = lstm_model.to(device)\n",
    "    lstm_model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=1e-5)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for data in dataloader:\n",
    "            x,y = [t.to(device) for t in data]\n",
    "            x = x.double()\n",
    "            y = y.double()\n",
    "            lstm_optimizer.zero_grad()\n",
    "            output, attention = lstm_model(x)\n",
    "            y = y.long()\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            lstm_optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch:',epoch+1,'loss=',running_loss)\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfidf_model(dataloader):\n",
    "    tfidf_model = TFIDFmodel()\n",
    "    tfidf_model = tfidf_model.float()\n",
    "    tfidf_model = tfidf_model.to(device)\n",
    "    tfidf_model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    tfidf_optimizer = optim.Adam(tfidf_model.parameters(), lr=1e-5)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for data in dataloader:\n",
    "            x,y = [t.to(device) for t in data]\n",
    "            x = x.float()\n",
    "            y = y.float()\n",
    "            tfidf_optimizer.zero_grad()\n",
    "            output = tfidf_model(x)\n",
    "            y = y.long()\n",
    "            loss = criterion(output, y)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            tfidf_optimizer.step()\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(running_loss))\n",
    "    return tfidf_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_unlabel_dataset(Dataset):\n",
    "    def __init__(self,x):\n",
    "        self.x = x\n",
    "        self.len = x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        return x\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Lstm_unlabel_dataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "#         print(type(x))\n",
    "        self.x = torch.from_numpy(x)\n",
    "#         print(type(self.x))\n",
    "        self.len = self.x.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        return x\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "def create_tfidf_unlabel_dataloader_dataset(x):\n",
    "#     BATCH_SIZE = 16\n",
    "    unlabel_tfidf_trainset = TFIDF_unlabel_dataset(x)\n",
    "    unlabel_tfidf_trainloader = DataLoader(unlabel_tfidf_trainset,batch_size=BATCH_SIZE,drop_last=True)\n",
    "    return unlabel_tfidf_trainset,unlabel_tfidf_trainloader\n",
    "\n",
    "def create_lstm_unlabel_dataloader_dataset(x):\n",
    "#     BATCH_SIZE = 16\n",
    "    unlabel_lstm_trainset = Lstm_unlabel_dataset(x)\n",
    "    unlabel_lstm_trainloader = DataLoader(unlabel_lstm_trainset,batch_size = BATCH_SIZE,drop_last=True)\n",
    "    return unlabel_lstm_trainset , unlabel_lstm_trainloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_lstm(model,dataloader):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            \n",
    "#             print(data.shape)\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            print(type(data))\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                x = data.to(device)\n",
    "            x = x.double()\n",
    "            outputs, state  = model(x)\n",
    "            after_softmax = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    return predictions_withoutmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_lstm_testing(model,dataloader):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                x,y = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            x = x.double()\n",
    "            outputs , state  = model(x)\n",
    "            after_softmax = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    return predictions_withoutmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_tfidf(model,dataloader):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                x = data.to(device)\n",
    "            x = x.float()\n",
    "            outputs = model(x)\n",
    "            after_softmax = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    return predictions_withoutmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_tfidf_testing(model,dataloader):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                x,y = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\n",
    "            x = x.float()\n",
    "            outputs = model(x)\n",
    "            after_softmax = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    return predictions_withoutmax\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_high_confidence_data(lstm_result,tfidf_result):\n",
    "    baseline = 0.7\n",
    "    print(lstm_result.shape)\n",
    "    print(tfidf_result.shape)\n",
    "    count = 0\n",
    "    li = []\n",
    "    y = []\n",
    "    print(lstm_result.shape[0])\n",
    "    for i in range(lstm_result.shape[0]):\n",
    "        _lstm = lstm_result[i]\n",
    "        _tfidf = tfidf_result[i]\n",
    "#         if lstm max value's index equals to tfidf's\n",
    "        lstm_val , lstm_index = torch.max(_lstm, 0)\n",
    "        tfidf_val , tfidf_index = torch.max(_tfidf, 0)\n",
    "        if lstm_index.item() == tfidf_index.item():\n",
    "            count+=1\n",
    "            if lstm_val.item()>=baseline and tfidf_val.item()>=baseline:\n",
    "                li.append(i)\n",
    "                y.append(lstm_index.item())\n",
    "    print(count)\n",
    "    return np.array(li),np.array(y)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def co_training():\n",
    "# #     Define some parameter\n",
    "# #     BATCH_SIZE = 16\n",
    "    \n",
    "for i in range(50):\n",
    "    if i==0:\n",
    "    #     init lstm label data\n",
    "        label_lstm_x =  lstm_train_x\n",
    "        label_lstm_y = lstm_train_y\n",
    "#         print(type(label_lstm_x))\n",
    "#         print('before label_lstm.shape:',label_lstm_x.shape,label_lstm_y.shape)\n",
    "\n",
    "    #     init tfidf label data\n",
    "        label_tfidf_x = tfidf_train_x\n",
    "        label_tfidf_y = tfidf_train_y\n",
    "#         print(type(label_tfidf_x))\n",
    "#         print('before label_tfidf.shape:',label_tfidf_x.shape,label_tfidf_y.shape)\n",
    "\n",
    "\n",
    "    #     init lstm unlabel data\n",
    "        unlabel_lstm_x = unlabel_for_lstm\n",
    "    #     init tfidf unlabel data\n",
    "        unlabel_tfidf_x = unlabel_for_tfidf\n",
    "#         print(type(unlabel_lstm_x))\n",
    "#         print(type(unlabel_tfidf_x))\n",
    "#         print('before unlabel_shape:',unlabel_lstm_x.shape,unlabel_tfidf_x.shape)\n",
    "    \n",
    "#     create lstm label trainset and trainloader\n",
    "    lstm_trainset = Lstmdataset(label_lstm_x , label_lstm_y)\n",
    "    lstm_trainloader = DataLoader(lstm_trainset,batch_size=BATCH_SIZE,drop_last=True)\n",
    "    \n",
    "#     create tfidf label trainset and trainloader\n",
    "    tfidf_trainset = TFIDFdataset(label_tfidf_x,label_tfidf_y)\n",
    "    tfidf_trainloader = DataLoader(tfidf_trainset,batch_size=BATCH_SIZE,drop_last=True)\n",
    "    \n",
    "#     create unlabel trainset and trainloader\n",
    "    unlabel_lstm_trainset, unlabel_lstm_trainloader = create_lstm_unlabel_dataloader_dataset(unlabel_lstm_x)\n",
    "    unlabel_tfidf_trainset,unlabel_tfidf_trainloader = create_tfidf_unlabel_dataloader_dataset(unlabel_tfidf_x)\n",
    "    \n",
    "#     start co-training \n",
    "\n",
    "#   some judgement here\n",
    "\n",
    "\n",
    "#   using data to train lstm and tfidf model\n",
    "    lstm_model = train_lstm_model(lstm_trainloader)\n",
    "    tfidf_model = train_tfidf_model(tfidf_trainloader)\n",
    "    \n",
    "#     get predict result from model\n",
    "    lstm_predict_result = predict_model_lstm(lstm_model, unlabel_lstm_trainloader)\n",
    "    tfidf_predict_result = predict_model_tfidf(tfidf_model, unlabel_tfidf_trainloader)\n",
    "#     choose which unlabel data should be moved to label data\n",
    "\n",
    "    idx , y = pick_high_confidence_data(lstm_predict_result,tfidf_predict_result)\n",
    "    \n",
    "# #     update unlabel data\n",
    "\n",
    "    unlabel_be_chosen_tfidf = np.take(unlabel_tfidf_x, idx, 0) \n",
    "    unlabel_be_chosen_lstm = np.take(unlabel_lstm_x, idx, 0) \n",
    "    \n",
    "    unlabel_tfidf_x = np.delete(unlabel_tfidf_x, idx, axis=0)\n",
    "    unlabel_lstm_x = np.delete(unlabel_lstm_x, idx, axis=0)\n",
    "    \n",
    "    print(unlabel_be_chosen_lstm.shape,type(unlabel_be_chosen_lstm))\n",
    "    print(unlabel_be_chosen_tfidf.shape,type(unlabel_be_chosen_tfidf))\n",
    "\n",
    "    \n",
    "    \n",
    "    label_lstm_x =  np.concatenate((label_lstm_x,unlabel_be_chosen_lstm))\n",
    "    label_lstm_y = np.concatenate((label_lstm_y , y))\n",
    "    \n",
    "    label_tfidf_x =  np.concatenate((label_tfidf_x , unlabel_be_chosen_tfidf))\n",
    "    label_tfidf_y = np.concatenate((label_tfidf_y , y))\n",
    "    \n",
    "    print('after combine label_lstm.shape:',label_lstm_x.shape,label_lstm_y.shape)\n",
    "    print('after combine label_tfidf.shape:',label_tfidf_x.shape,label_tfidf_y.shape)\n",
    "    print('after unlabel_shape:',unlabel_lstm_x.shape,unlabel_tfidf_x.shape)\n",
    "    \n",
    "    torch.save(lstm_model, 'lstm_model_cotraining.pkl')\n",
    "    torch.save(tfidf_model, 'tfidf_model_cotraining.pkl')\n",
    "    \n",
    "    \n",
    "    indices = np.arange(label_lstm_x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    label_lstm_x = label_lstm_x[indices]\n",
    "    label_lstm_y = label_lstm_y[indices]\n",
    "    \n",
    "    label_tfidf_x = label_tfidf_x[indices]\n",
    "    label_tfidf_y = label_tfidf_y[indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:559: UserWarning: Couldn't retrieve source code for container of type BiLSTM_Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTM_Attention(\n",
       "  (lstm): LSTM(300, 128, bidirectional=True)\n",
       "  (out): Linear(in_features=256, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = torch.load('lstm_model_cotraining.pkl')\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:559: UserWarning: Couldn't retrieve source code for container of type TFIDFmodel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFIDFmodel(\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = torch.load('tfidf_model_cotraining.pkl')\n",
    "tfidf_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_x = x_lstm[5000:10000]\n",
    "lstm_test_y = labels[5000:10000]\n",
    "\n",
    "lstm_testset = Lstmdataset(lstm_test_x , test_y)\n",
    "lstm_testloader = DataLoader(lstm_testset,batch_size=BATCH_SIZE,drop_last=True)\n",
    "    \n",
    "#     create tfidf label trainset and trainloader\n",
    "tfidf_testset = TFIDFdataset(tfidf_test_x, test_y)\n",
    "tfidf_testloader = DataLoader(tfidf_testset,batch_size=BATCH_SIZE,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predict_result = predict_model_lstm_testing(lstm_model , lstm_testloader)\n",
    "tfidf_predict_result = predict_model_tfidf_testing(tfidf_model, tfidf_testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predict = lstm_predict_result + tfidf_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , ans =torch.max(final_predict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = torch.Tensor.cpu(ans).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7364"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ans ==test_y).sum()/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
