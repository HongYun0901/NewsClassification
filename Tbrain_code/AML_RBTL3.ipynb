{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"AML_RBTL3.ipynb","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fb844be23e1841069a73138e8f89b672":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5859cac5ebdf450f97618c51f767fb1b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5a7b50c342324437823c76aa0b09b467","IPY_MODEL_ad259e74ac8e47c8839df5908e216bb8"]}},"5859cac5ebdf450f97618c51f767fb1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a7b50c342324437823c76aa0b09b467":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a28e2aefa1f94b6cbeb6ab1e7137553b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109540,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109540,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04da6279a9544cea89e1d818d3b35fea"}},"ad259e74ac8e47c8839df5908e216bb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e303299bc2d545c0b63ba8de1438d067","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110k/110k [00:00&lt;00:00, 285kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0681e0101f04a78a3a6a31f78574af8"}},"a28e2aefa1f94b6cbeb6ab1e7137553b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04da6279a9544cea89e1d818d3b35fea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e303299bc2d545c0b63ba8de1438d067":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d0681e0101f04a78a3a6a31f78574af8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"387ba01f1bfa450bb8e4a4f8511e634a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dd076452e6094d169dd310267f12ccef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_98c175b48a2d4705ab4d04a38e579df5","IPY_MODEL_cbe97d55750c47a4ba430b5555d97746"]}},"dd076452e6094d169dd310267f12ccef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98c175b48a2d4705ab4d04a38e579df5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7e919c16d268469e837b9dfe314cd04a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b64166f6807469bb7aae16e2c8ef59a"}},"cbe97d55750c47a4ba430b5555d97746":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6c869e7ff1a41b2b7f8398f3a9bb660","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 60.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b5dbabd6eb24fb3a91ce24567621b7a"}},"7e919c16d268469e837b9dfe314cd04a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3b64166f6807469bb7aae16e2c8ef59a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6c869e7ff1a41b2b7f8398f3a9bb660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b5dbabd6eb24fb3a91ce24567621b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"526f74f736c242baa5a36c303c0ece4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_03dc44b03a9f4ae69b6c9a5e5d93e6ad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fbdb923713284c2d9ef3f8662af555c6","IPY_MODEL_7e1d79dac39e4d82bf960f4b5e8e828d"]}},"03dc44b03a9f4ae69b6c9a5e5d93e6ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbdb923713284c2d9ef3f8662af555c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33da2a6dd8fe4cd8982494743551c654","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e118295caab647e885756b0d4a66ee97"}},"7e1d79dac39e4d82bf960f4b5e8e828d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7d7b0e0c06449ef897b75338e324d59","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 196B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16c20f96b7374d2288afd4201a2a92d3"}},"33da2a6dd8fe4cd8982494743551c654":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e118295caab647e885756b0d4a66ee97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7d7b0e0c06449ef897b75338e324d59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"16c20f96b7374d2288afd4201a2a92d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9adf8d59f41d46259dfcd6b364e57853":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_823a997792da4c109076232c685c1d7a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b16dbc5e16144abb8e057a94909c8fc7","IPY_MODEL_b2a0d1cd844a46138199748172f96bf9"]}},"823a997792da4c109076232c685c1d7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b16dbc5e16144abb8e057a94909c8fc7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9794e3def0f6479388186bf267f2874e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":19,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":19,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eedebc8a3ffa43038c2baeb764931142"}},"b2a0d1cd844a46138199748172f96bf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0871b66dae214651ba054af10bd80915","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 19.0/19.0 [00:00&lt;00:00, 98.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa2eeec171684375866658e9da986f2f"}},"9794e3def0f6479388186bf267f2874e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eedebc8a3ffa43038c2baeb764931142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0871b66dae214651ba054af10bd80915":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa2eeec171684375866658e9da986f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"d-TQ1Au_RJjm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1595244222862,"user_tz":-480,"elapsed":23563,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"d5fd8e5f-7bc4-4b61-c5ed-c3e6c24f4661"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/bin/bash: google-drive-ocamlfuse: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hLq7qmjdRL9I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595244222863,"user_tz":-480,"elapsed":23024,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"74e883ee-5a84-4d6b-f1e1-098f2b0cfc90"},"source":["cd /content/drive/My Drive/Colab Notebooks/AML"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/AML\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ye3ig1jEi92L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"status":"ok","timestamp":1595244235903,"user_tz":-480,"elapsed":34920,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"68550f62-5a1d-4e21-a6b0-426f6330cc19"},"source":["! pip install zhon\n","! pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting zhon\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/b0/c56c6079ad47c35a2341440818b6620de8c46a265ed690a51b1a4e5591bc/zhon-1.1.5.tar.gz (99kB)\n","\r\u001b[K     |███▎                            | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: zhon\n","  Building wheel for zhon (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhon: filename=zhon-1.1.5-cp36-none-any.whl size=84293 sha256=854170aad2cdc9f502c4a854ed7fad58ce9a11e73d4426f433a76d8e4425ccde\n","  Stored in directory: /root/.cache/pip/wheels/0e/93/5a/ad2f403c359ba996e33c21bf18611d921413df9740ede2fcf4\n","Successfully built zhon\n","Installing collected packages: zhon\n","Successfully installed zhon-1.1.5\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 3.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 22.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 18.6MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 19.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=ce3f5b892b344b8c040356e95c5d0dc77d84fc1f1587c5b09da2230529e9cf44\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mf3EflIBRILC","colab_type":"text"},"source":["# Data Preprocessing\n","## basic"]},{"cell_type":"code","metadata":{"tags":[],"id":"f47gpSwLRILD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595244240206,"user_tz":-480,"elapsed":1408,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"7fa9124e-be0e-4b78-baf2-d80a8f0241c4"},"source":["import pandas as pd\n","import ast\n","import numpy as np\n","import re\n","from zhon.hanzi import stops\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","PRETRAINED_MODEL_NAME = \"hfl/rbtl3\" # RBTL3\n","df_train = pd.read_csv('./dataset/multi_tbrain_train.csv')\n","df_test = pd.read_csv('./dataset/multi_tbrain_test.csv')\n","df_train = df_train.fillna('[\\'\\]')\n","df_test = df_test.fillna('[\\'\\']')\n","print(df_train.shape)\n","print(df_test.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(4426, 4)\n","(491, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YOO0iT-SRILK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244240207,"user_tz":-480,"elapsed":706,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def clean_string(content):\n","#     cc = OpenCC('t2s')\n","    content = content.replace('\\n','。').replace('\\t','，').replace('!', '！').replace('?', '？')# erease white space cause English name error\n","    content = re.sub(\"[+\\.\\/_,$%●▼►^*(+\\\"\\']+|[+——~@#￥%……&*（）★]\", \"\",content)\n","    content = re.sub(r\"[%s]+\" %stops, \"。\",content)\n","#     content = cc.convert(content)\n","    return content"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCS6r7fQRILO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244240208,"user_tz":-480,"elapsed":486,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def find_all(name, content):\n","    # +1 for [CLS]\n","    pos_list = [m.start()+1 for m in re.finditer(name, content)]\n","    count = len(pos_list)\n","    return pos_list , count"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzAZ4mBzRILS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244241599,"user_tz":-480,"elapsed":545,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def orgi_2_array(names, contents):\n","    x = []\n","    binary_y = []\n","    BIO_labels = []\n","    nFound_count = 0\n","    name_count = 0\n","    \n","    for i in range(len(contents)):\n","        content = contents[i]\n","        content = clean_string(content)\n","\n","        # record names\n","        # name = names[i] # single\n","        name_list = names[i]\n","        names_label = ast.literal_eval(name_list) # string to list\n","        # debug\n","        \n","\n","        # init pos label arr\n","        BIO_label = np.full((512), 2) # initial to all 2 (outside)\n","        \n","        # no AML person\n","        if(name_list == '[]'):\n","            binary_y.append(0)\n","            x.append(content)\n","            BIO_label[0] = 0 # first position 0(begin)\n","            BIO_labels.append(BIO_label)\n","\n","        else:\n","            # initial position list\n","            start_pos = []\n","            end_pos = []\n","\n","            # if (True): # single\n","            for name in names_label:\n","              temp, count = find_all(name, content)\n","              if(temp == []):\n","  #                 print(name + ' find error in data', i)\n","                  nFound_count += 1\n","                  continue\n","              for j in range(count):\n","                start_pos.append(temp[j])\n","                end_pos.append(temp[j] + len(name))\n","\n","#                  01234\n","#                B 00100\n","#                I 00011\n","#                O 11000\n","            if (i == 6):\n","              print(start_pos)\n","              print(end_pos)\n","            for j in range(len(start_pos)):\n","                if(start_pos[j] < 512 and end_pos[j] < 512):\n","                    BIO_label[start_pos[j]] = 0\n","                    BIO_label[start_pos[j]+1 : end_pos[j]] = 1\n","            binary_y.append(1)\n","            x.append(content)\n","            BIO_labels.append(BIO_label)\n","            \n","\n","    x = np.array(x)\n","    binary_y = np.array(binary_y)\n","    BIO_labels = np.array(BIO_labels)\n","    \n","    print('nFound: ', nFound_count)\n","    print('name_count:', name_count)\n","    print(x.shape)\n","    print(binary_y.shape)\n","#     print(begin_pos_labels.shape)\n","#     print(inside_pos_labels.shape)\n","#     print(outside_pos_labels.shape)\n","    print(BIO_labels.shape)\n","    return x, binary_y, BIO_labels"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bNbG1YCCocSR","colab_type":"text"},"source":["## Get Data List (Train)"]},{"cell_type":"code","metadata":{"id":"xgxsXLjgRILW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1595178971504,"user_tz":-480,"elapsed":4151,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"b327de91-d43d-4874-ac93-988d05b9421a"},"source":["names =  df_train['name']\n","contents = np.array(df_train['full_content'].tolist())\n","train_x, train_binary_y, train_bio_labels = orgi_2_array(names, contents)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[1, 151, 187, 191, 195, 183, 71]\n","[4, 154, 190, 194, 198, 186, 74]\n","nFound:  0\n","name_count: 0\n","(4426,)\n","(4426,)\n","(4426, 512)\n","nFound:  0\n","name_count: 0\n","(491,)\n","(491,)\n","(491, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"f2KfiQ36RILa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595178971505,"user_tz":-480,"elapsed":1627,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"453e6992-2011-4815-e7c1-74934d3adaa6"},"source":["print(len(train_x),len(train_binary_y))\n","print(sum(train_binary_y)/len(train_x))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["4426 4426\n","0.07568910980569363\n","491 491\n","0.07535641547861507\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aTOdgmlcluhL","colab_type":"code","colab":{}},"source":[" for i in range(len(test_binary_y)):\n","    if (test_binary_y[i] == 1):\n","        print(\"i=\",i)\n","        print(test_x[i])\n","        print(test_binary_y[i])\n","        print(test_bio_labels[i])\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_prpyiUxRILf","colab_type":"text"},"source":["## Dataset Class"]},{"cell_type":"code","metadata":{"id":"gDGrE3spRILg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244246496,"user_tz":-480,"elapsed":3467,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, input_dict, y , bio_labels):\n","        self.input_ids = input_dict['input_ids']\n","        self.token_type_ids = input_dict['token_type_ids']\n","        self.attention_mask = input_dict['attention_mask']\n","        self.y = y\n","        self.bio_labels = bio_labels\n","        \n","    def __getitem__(self,idx):\n","        inputid = self.input_ids[idx]\n","        tokentype = self.token_type_ids[idx]\n","        attentionmask = self.attention_mask[idx]\n","        bio_label = self.bio_labels[idx]\n","        y = self.y[idx]\n","        return inputid , tokentype , attentionmask, y , bio_label\n","    \n","    def __len__(self):\n","        return len(self.input_ids)\n","    \n","class TestDataset(Dataset):\n","    def __init__(self, input_dict):\n","        self.input_ids = input_dict['input_ids']\n","        self.token_type_ids = input_dict['token_type_ids']\n","        self.attention_mask = input_dict['attention_mask']\n","        \n","    def __getitem__(self,idx):\n","        inputid = self.input_ids[idx]\n","        tokentype = self.token_type_ids[idx]\n","        attentionmask = self.attention_mask[idx]\n","        return inputid , tokentype , attentionmask, \n","    \n","    def __len__(self):\n","        return len(self.input_ids)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u0TjewOuRILk","colab_type":"text"},"source":["## Go Through Tokenizer (Train)"]},{"cell_type":"code","metadata":{"id":"PR3fIw2KqesN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595178592913,"user_tz":-480,"elapsed":71550,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["from transformers import BertTokenizer\n","\n","\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","# 把input轉換成bert格式\n","train_input_dict = tokenizer.batch_encode_plus(train_x, \n","                                         add_special_tokens=True,\n","                                         max_length=512,\n","                                         return_special_tokens_mask=True,\n","                                         pad_to_max_length=True,\n","                                         return_tensors='pt',\n","                                         truncation=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jwhYlA_qgwb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595178592915,"user_tz":-480,"elapsed":70941,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["import torch\n","torch.save(train_input_dict, 'train_input_dict.pickle')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"iotFZXJPRILm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595178978543,"user_tz":-480,"elapsed":3060,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["import torch\n","train_input_dict = torch.load('train_input_dict.pickle')"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ntuaz0TXRILp","colab_type":"text"},"source":["## Model Budling"]},{"cell_type":"code","metadata":{"id":"_9gzlkNxRILq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244248643,"user_tz":-480,"elapsed":3001,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["\"\"\" model budling \"\"\"\n","from transformers import BertModel\n","import torch\n","import torch.nn as nn\n","\n","class AMLPredictModel(nn.Module):\n","    def __init__(self, config):\n","        super(AMLPredictModel, self).__init__()\n","        self.bert = BertModel.from_pretrained(PRETRAINED_MODEL_NAME, config = config)\n","        self.classifier = nn.Sequential(\n","                        nn.Linear(config.hidden_size, 2),\n","        ) # binary classification\n","        self.BIO_classifier = nn.Sequential(\n","                        nn.Linear(config.hidden_size, 3),\n","        ) # BIO tagging\n","        self.sigmoid = nn.Sigmoid()\n","        self.softmax = nn.Softmax(-1)\n","\n","    def forward(self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","#         position_ids=None,\n","#         head_mask=None,\n","#         inputs_embeds=None,\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","#             position_ids=position_ids,\n","#             head_mask=head_mask,\n","#             inputs_embeds=inputs_embeds\n","        )\n","        have_AML = outputs[1] # pooled cls (cls token through 1 linear and tanh)\n","        have_AML = self.classifier(have_AML)\n","        BIO = self.BIO_classifier(outputs[0]) # 512*HIDDENSIZE word vectors\n","        BIO = self.softmax(BIO)\n","        \n","#         flag = 1\n","        # debug\n","#         if (flag):\n","#             flag = 0\n","#             print(\"forward output\")\n","#             print(BIO)\n","#             print(BIO_out)\n","#             print(arg)\n","#             print(\"---\")\n","        \n","        outputs = (have_AML, BIO) + outputs[2:]\n","        return outputs"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mvE2_BOo2aP","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"4G9SDDTCRILy","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595178979821,"user_tz":-480,"elapsed":543,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def get_predictions(model, dataloader, compute_acc=False):\n","    predictions = None\n","    predictions_withoutmax = None\n","    binary_correct = 0\n","    total = 0\n","    bio_correct = 0\n","    with torch.no_grad():\n","        # 遍巡整個資料集\n","        for data in dataloader:\n","            # 將所有 tensors 移到 GPU 上\n","            if next(model.parameters()).is_cuda:\n","                data = [t.to(\"cuda:0\") for t in data if t is not None]\n","            \n","            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n","            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n","            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n","            outputs = model(input_ids=tokens_tensors, \n","                            token_type_ids=segments_tensors, \n","                            attention_mask=masks_tensors)\n","            \n","            logits = outputs[0] # haveAML(binary classification)\n","            after_softmax = nn.functional.softmax(logits.data, dim=1)\n","            _, binary_pred = torch.max(after_softmax, 1)\n","\n","            temp = outputs[1]\n","            bio_preds = torch.empty(temp.shape[0], 3, 512)\n","            \n","            for i in range(temp.shape[0]):  # run batchsize times\n","              arg = temp[i].argmax(1) # 3*512 into class label\n","              bio_preds[i] = arg\n","\n","            bio_preds = np.array(bio_preds)\n","\n","            # debug\n","            print(\"get pred\")\n","            print(\"b_pred \", binary_pred)\n","            # print(binary_pred.shape)\n","            # print(\"-----\")\n","            # print(\"b_label \", data[3])\n","            # print(data[3].shape)\n","            print(\"BIO_labels \", data[4])\n","            print(data[4].shape)\n","            # print(\"---\")\n","            print(\"BIO_pred \",bio_preds)\n","            # print(bio_preds.shape)\n","            # break\n","            \n","            # 用來計算訓練集的分類準確率\n","            if compute_acc:\n","                binary_labels = data[3]\n","                total += binary_labels.size(0)\n","                binary_correct += (binary_pred == binary_labels).sum().item()\n","                bio_labels = data[4]\n","                bio_correct += (bio_preds == bio_labels).sum().item()\n","                # print(binary_correct)\n","                # break\n","\n","                \n","            # 將當前 batch 記錄下來\n","            if predictions is None:\n","                predictions = binary_pred\n","            else:\n","                predictions = torch.cat((predictions, binary_pred))\n","                \n","            if predictions_withoutmax is None:\n","                predictions_withoutmax = after_softmax\n","            else:\n","                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n","    \n","    if compute_acc:\n","        binary_acc = binary_correct / total\n","        bio_acc = bio_correct / total\n","        return predictions, binary_acc, bio_acc\n","    return predictions_withoutmax"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"MnV2_agYRILu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1595178988270,"user_tz":-480,"elapsed":6104,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"5bc5d2c1-89d6-45b6-bd50-1ce32ef5f9db"},"source":["\"\"\" model setting (training)\"\"\"\n","from transformers import BertConfig, AdamW\n","config = BertConfig.from_pretrained(PRETRAINED_MODEL_NAME, output_hidden_states=True)\n","BATCH_SIZE = 4\n","trainSet = TrainDataset(train_input_dict, train_binary_y, train_bio_labels)\n","trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)\n","model = AMLPredictModel(config)\n","optimizer = AdamW(model.parameters(), lr=1e-5) # AdamW = BertAdam\n","binary_loss_fct = nn.CrossEntropyLoss()\n","weight = torch.FloatTensor([500,450,1]).cuda()\n","BIO_loss_fct = nn.CrossEntropyLoss(weight=weight)\n","\n","# high-level 顯示此模型裡的 modules\n","print(\"\"\"\n","name            module\n","----------------------\"\"\")\n","for name, module in model.named_children():\n","    if name == \"bert\":\n","        for n, _ in module.named_children():\n","            print(f\"{name}:{n}\")\n","#             print(_)\n","    else:\n","        print(\"{:15} {}\".format(name, module))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["device: cuda:0\n","\n","name            module\n","----------------------\n","bert:embeddings\n","bert:encoder\n","bert:pooler\n","classifier      Sequential(\n","  (0): Linear(in_features=1024, out_features=2, bias=True)\n",")\n","BIO_classifier  Sequential(\n","  (0): Linear(in_features=1024, out_features=3, bias=True)\n",")\n","sigmoid         Sigmoid()\n","softmax         Softmax(dim=-1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fyGsurI76_nr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595178988273,"user_tz":-480,"elapsed":1650,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["model = torch.load('./model/RBTL3_bio_EPOCHES_4.pkl')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"N-Uw9qeDRIL1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1595179839928,"user_tz":-480,"elapsed":634365,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"a7523597-4014-46ea-dfb1-f63c287889d5"},"source":["\"\"\" training \"\"\"\n","model = model.to(device)\n","model.train() ##########################\n","\n","EPOCHS = 10\n","step = 0\n","for epoch in range(5, EPOCHS):\n","    running_loss = 0.0\n","    binary_running_loss = 0.0\n","    BIO_running_loss = 0.0\n","    for data in trainLoader:\n","    # data = testSet[21] # test model\n","    # if(True):\n","        \n","      tokens_tensors, segments_tensors, masks_tensors, \\\n","      labels, BIO_label = [t.to(device) for t in data]\n","\n","      # tokens_tensors, segments_tensors, masks_tensors, labels, BIO_label = data\n","      # tokens_tensors, segments_tensors, masks_tensors = data\n","      # tokens_tensors = tokens_tensors.reshape((1,512)).to(device)\n","      # segments_tensors = segments_tensors.reshape((1,512)).to(device)\n","      # masks_tensors = masks_tensors.reshape((1,512)).to(device)\n","      # labels = torch.tensor(labels).reshape((1)).to(device)\n","      # BIO_label = torch.tensor(BIO_label).reshape((1,512)).to(device)\n","\n","      # 將參數梯度歸零\n","      optimizer.zero_grad()\n","      \n","      # forward pass\n","      outputs = model(input_ids=tokens_tensors, \n","                      token_type_ids=segments_tensors, \n","                      attention_mask=masks_tensors)\n","\n","      BIO_pred = outputs[1]\n","      BIO_pred = torch.transpose(BIO_pred, 1, 2)\n","      \n","      # debug\n","      # print(\"epoch output\")\n","      # BIO_label[0][0] = 500\n","      # BIO_label = BIO_label.squeeze()\n","      # BIO_pred = BIO_pred.squeeze()\n","      # print(BIO_label)\n","      # print(BIO_label.shape)\n","      # print(BIO_pred)\n","      # print(BIO_pred.shape)\n","      # print(outputs[0].shape)\n","      # print(labels.shape)\n","      # print(BIO_pred[0][0])\n","      # print(BIO_pred[0][1])\n","      # print(BIO_pred[0][2])\n","      # break\n","\n","\n","      binary_loss = binary_loss_fct(outputs[0], labels)\n","      # print(BIO_pred.shape)\n","      # print(BIO_label.shape)\n","      BIO_loss = BIO_loss_fct(BIO_pred, BIO_label)\n","      # print(binary_loss, BIO_loss)\n","      loss = binary_loss + BIO_loss\n","      # print(loss)\n","      # break\n","      \n","      # backward\n","      # loss.backward()\n","      # optimizer.step()\n","\n","      # 紀錄當前 batch loss\n","      running_loss += loss.item()\n","      binary_running_loss += binary_loss.item()\n","      BIO_running_loss += BIO_loss.item()\n","      # if (step % 10 == 0):\n","        # print('step %d total_loss: %.3f binary_loss: %.3f BIO_loss: %.3f' %\n","        #     (step, running_loss, binary_running_loss, BIO_running_loss))\n","      step += 1\n","        \n","    CHECKPOINT_NAME = './model/RBTL3_bio_EPOCHES_' + str(epoch) + '.pkl'\n","    torch.save(model, CHECKPOINT_NAME)\n","        \n","    # 計算分類準確率\n","    # _, binary_acc, bio_acc = get_predictions(model, trainLoader, compute_acc=True)\n","\n","    print('[epoch %d] loss: %.3f, binary_loss: %.3f, bio_loss: %.3f' %\n","          (epoch + 1, running_loss, binary_running_loss, BIO_running_loss))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type AMLPredictModel. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["[epoch 6] loss: 672.031, binary_loss: 0.110, bio_loss: 671.921\n","[epoch 7] loss: 671.320, binary_loss: 0.114, bio_loss: 671.206\n","[epoch 8] loss: 671.564, binary_loss: 0.160, bio_loss: 671.403\n","[epoch 9] loss: 671.603, binary_loss: 0.138, bio_loss: 671.465\n","[epoch 10] loss: 671.443, binary_loss: 0.274, bio_loss: 671.168\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0WSwVmiBRIL5","colab_type":"text"},"source":["---\n","## testing"]},{"cell_type":"code","metadata":{"id":"XnTi_GkuEvxu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1595240344249,"user_tz":-480,"elapsed":1035,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"0fc1d9b5-ffdd-4de3-d163-1aee3bc8e4fe"},"source":["df_test"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>news_ID</th>\n","      <th>name</th>\n","      <th>full_content</th>\n","      <th>ckip_names</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2385</td>\n","      <td>[]</td>\n","      <td>理財\\n2019.12.04 12:58\\n【和潤申購熱3】下一檔和潤是誰？　達人點名注意它...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3051</td>\n","      <td>[]</td>\n","      <td>國際中心／綜合報導\\n日前網路上瘋傳一張照片，只見一名發現墳墓、身穿單車裝備的外籍男子，雙腿...</td>\n","      <td>['Charmig', 'Anthon Charmig']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4547</td>\n","      <td>[]</td>\n","      <td>焦點\\n2019.10.22 15:36\\n1億粉絲網紅談港遭封殺　為中網友抱屈「看不到我的...</td>\n","      <td>['PewDiePie ', '聰哥', 'PewDiePie']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1628</td>\n","      <td>[]</td>\n","      <td>台灣殺人案疑犯陳同佳就洗黑錢案昨日（23日）刑滿出獄，向死者潘曉穎的家人道歉並表示願意到台灣...</td>\n","      <td>['商台', '陳同佳', '潘曉穎', '邱垂正', '陳', '梁美芬', '管浩鳴',...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3818</td>\n","      <td>[]</td>\n","      <td>企業一年一度都要根據基本假設與關鍵因素，來展開次年度的預算。查現在企業預算，通常是由財務部門...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>486</th>\n","      <td>3635</td>\n","      <td>[]</td>\n","      <td>MSCI 宣布取消在港交所掛牌的雅高控股 (3313-HK) 列入中國指數權重股，突如其來的...</td>\n","      <td>['鼎益豐']</td>\n","    </tr>\n","    <tr>\n","      <th>487</th>\n","      <td>1608</td>\n","      <td>['王懷恭']</td>\n","      <td>騙老人家投資靈骨塔 黑幫爽開保時捷被抄\\n警方特別查扣王嫌的名貴進口車，以方便未來被害人求償...</td>\n","      <td>['劉慶侯', '王懷恭']</td>\n","    </tr>\n","    <tr>\n","      <th>488</th>\n","      <td>1517</td>\n","      <td>[]</td>\n","      <td>香港大學法律系教授張善喻今日（9日）在港台節目《香港家書》中表示，法庭近期頻發臨時禁制令，所...</td>\n","      <td>['張善喻']</td>\n","    </tr>\n","    <tr>\n","      <th>489</th>\n","      <td>907</td>\n","      <td>[]</td>\n","      <td>2019.07.17 11:01\\n【投資夯情報】秒懂ETN幫你把小錢變大\\n看過《蟻人》的...</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>490</th>\n","      <td>486</td>\n","      <td>[]</td>\n","      <td>【13:45】示威者返回遮打花園後和平散去。歷時約45分鐘的「快閃」遊行期間，未見有警察戒備...</td>\n","      <td>['黃旗指', 'Keith', '陳', 'Sonia']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>491 rows × 4 columns</p>\n","</div>"],"text/plain":["     news_ID  ...                                         ckip_names\n","0       2385  ...                                                 []\n","1       3051  ...                      ['Charmig', 'Anthon Charmig']\n","2       4547  ...                  ['PewDiePie ', '聰哥', 'PewDiePie']\n","3       1628  ...  ['商台', '陳同佳', '潘曉穎', '邱垂正', '陳', '梁美芬', '管浩鳴',...\n","4       3818  ...                                                 []\n","..       ...  ...                                                ...\n","486     3635  ...                                            ['鼎益豐']\n","487     1608  ...                                     ['劉慶侯', '王懷恭']\n","488     1517  ...                                            ['張善喻']\n","489      907  ...                                                 []\n","490      486  ...                     ['黃旗指', 'Keith', '陳', 'Sonia']\n","\n","[491 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"ATDm-9ZGqnOB","colab_type":"code","colab":{}},"source":["temp = df_test['name'].tolist()\n","ans = []\n","for i in range(len(temp)):\n","  t = ast.literal_eval(temp[i])\n","  if (len(t) == 0):\n","    t.append('')\n","  ans.append(t)\n","ans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGmYmQWSpChJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1595244257383,"user_tz":-480,"elapsed":514,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"c40727b2-c750-4735-c71f-dcbb894627a3"},"source":["names =  df_test['name']\n","contents = np.array(df_test['full_content'].tolist())\n","test_x, test_binary_y, test_bio_labels = orgi_2_array(names, contents)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["nFound:  0\n","name_count: 0\n","(491,)\n","(491,)\n","(491, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6lBWBRl9rw4D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["fb844be23e1841069a73138e8f89b672","5859cac5ebdf450f97618c51f767fb1b","5a7b50c342324437823c76aa0b09b467","ad259e74ac8e47c8839df5908e216bb8","a28e2aefa1f94b6cbeb6ab1e7137553b","04da6279a9544cea89e1d818d3b35fea","e303299bc2d545c0b63ba8de1438d067","d0681e0101f04a78a3a6a31f78574af8","387ba01f1bfa450bb8e4a4f8511e634a","dd076452e6094d169dd310267f12ccef","98c175b48a2d4705ab4d04a38e579df5","cbe97d55750c47a4ba430b5555d97746","7e919c16d268469e837b9dfe314cd04a","3b64166f6807469bb7aae16e2c8ef59a","c6c869e7ff1a41b2b7f8398f3a9bb660","8b5dbabd6eb24fb3a91ce24567621b7a","526f74f736c242baa5a36c303c0ece4a","03dc44b03a9f4ae69b6c9a5e5d93e6ad","fbdb923713284c2d9ef3f8662af555c6","7e1d79dac39e4d82bf960f4b5e8e828d","33da2a6dd8fe4cd8982494743551c654","e118295caab647e885756b0d4a66ee97","d7d7b0e0c06449ef897b75338e324d59","16c20f96b7374d2288afd4201a2a92d3","9adf8d59f41d46259dfcd6b364e57853","823a997792da4c109076232c685c1d7a","b16dbc5e16144abb8e057a94909c8fc7","b2a0d1cd844a46138199748172f96bf9","9794e3def0f6479388186bf267f2874e","eedebc8a3ffa43038c2baeb764931142","0871b66dae214651ba054af10bd80915","fa2eeec171684375866658e9da986f2f"]},"executionInfo":{"status":"ok","timestamp":1595244261948,"user_tz":-480,"elapsed":2298,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"12d3942d-84e3-4188-810b-c99ee7ddce45"},"source":["from transformers import BertTokenizer\n","\n","PRETRAINED_MODEL_NAME = \"hfl/rbtl3\" # RBTL3\n","\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb844be23e1841069a73138e8f89b672","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"387ba01f1bfa450bb8e4a4f8511e634a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"526f74f736c242baa5a36c303c0ece4a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9adf8d59f41d46259dfcd6b364e57853","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4HTrUZ6Ct98e","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595224777780,"user_tz":-480,"elapsed":8960,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["test_input_dict = tokenizer.batch_encode_plus(test_x, \n","                                         add_special_tokens=True,\n","                                         max_length=512,\n","                                         return_special_tokens_mask=True,\n","                                         pad_to_max_length=True,\n","                                         return_tensors='pt',\n","                                         truncation=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQFjyGympbZb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595224777781,"user_tz":-480,"elapsed":7583,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["import torch\n","torch.save(test_input_dict, 'test_input_dict.pickle')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJZiXTuwpbgl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244265643,"user_tz":-480,"elapsed":1207,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["import torch\n","test_input_dict = torch.load('test_input_dict.pickle')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5zN9utmvc19","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595245746764,"user_tz":-480,"elapsed":531,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def bio_2_string(tokens_tensors, have_AML, BIO_tagging, ckip_result):\n","  result = []\n","  if (have_AML.item() == 0):\n","    result.append('')\n","  else:\n","    for j in range(1, 512):\n","      if (BIO_tagging[j] == 0):\n","        start = j\n","        end = j + 1\n","        while (end < 512 and BIO_tagging[end] == 1):\n","          end += 1\n","        if (end > start + 1):\n","          s = tokenizer.decode(token_ids = tokens_tensors[start : end], skip_special_tokens = True)\n","          s = s.replace(' ', '')\n","          for k in range(len(ckip_result)):\n","            found = s.find(ckip_result[k])\n","            if (found != 1):\n","              result.append(ckip_result[k])\n","    if (len(result) == 0):\n","      result.append('')\n","  return result"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"zaeoDS0np-0S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595245747811,"user_tz":-480,"elapsed":599,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def get_predictions(model, testLoader, BATCH_SIZE):\n","  result = []\n","  total_count = 0 # 第n筆data\n","  with torch.no_grad():\n","    for data in testLoader:\n","      # 將所有 tensors 移到 GPU 上\n","      if next(model.parameters()).is_cuda:\n","        data = [t.to(\"cuda:0\") for t in data if t is not None]\n","      \n","      # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n","      # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n","      tokens_tensors, segments_tensors, masks_tensors = data[:3]\n","      outputs = model(input_ids=tokens_tensors, \n","                  token_type_ids=segments_tensors, \n","                  attention_mask=masks_tensors)\n","      \n","      # print(tokens_tensors, tokens_tensors.shape)\n","      # print(outputs[0], outputs[0].shape)\n","      # print(outputs[1], outputs[1].shape)\n","      \n","      count = min(outputs[0].shape[0], BATCH_SIZE)\n","      for i in range(count):  # run batchsize times\n","        have_AML = outputs[0][i].argmax()\n","        BIO_pred = outputs[1][i].argmax(1) # 3*512 into class label\n","        text_token = tokens_tensors[i]\n","        ckip_names = df_test.loc[total_count, 'name']\n","        ckip_names_list = ast.literal_eval(ckip_names) # string to list\n","        r = bio_2_string(text_token, have_AML, BIO_pred, ckip_names_list)\n","        # print(r)\n","        result.append(r)\n","        total_count += 1\n","      \n","        # print(text_token, text_token.shape)\n","        # print(have_AML, have_AML.shape)\n","        # print(BIO_pred, BIO_pred.shape)\n","        # print(\"recover\", tokenizer.decode(token_ids = tokens_tensors[0][1:5], skip_special_tokens = True))\n","      # break\n","    # print(result)\n","  return result"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkAJDq2Qt72t","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595245766915,"user_tz":-480,"elapsed":18504,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["\"\"\"testing\"\"\"\n","import torch\n","from transformers import BertConfig\n","config = BertConfig.from_pretrained(PRETRAINED_MODEL_NAME, output_hidden_states=True)\n","model = AMLPredictModel(config)\n","model = torch.load('./model/RBTL3_bio_EPOCHES_9.pkl')\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","model.eval()\n","\n","BATCH_SIZE = 64\n","testSet = TestDataset(test_input_dict)\n","testLoader = DataLoader(testSet, batch_size=BATCH_SIZE)\n","\n","\n","predictions = get_predictions(model, testLoader, BATCH_SIZE)\n","\n","# pred = predictions.cpu().data.numpy()\n","# pred = np.argmax(pred, axis=1)\n","# accuracy = (pred == test_binary_y).mean()\n","# print('Your test accuracy is %.6f' % (accuracy * 100))\n"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"1p5uEYssCYfD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595244325969,"user_tz":-480,"elapsed":578,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}}},"source":["def eval(pred, ans):\n","    if bool(pred) is not bool(ans):\n","        return 0\n","    elif not pred and not ans:\n","        return 1\n","    else:\n","        pred = set(pred)\n","        ans = set(ans)\n","        interaction_len = len(pred & ans)\n","        if interaction_len == 0:\n","            return 0\n","\n","        pred_len = len(pred)\n","        ans_len = len(ans)\n","        return 2 / (pred_len / interaction_len + ans_len / interaction_len)\n","\n","\n","def eval_all(pred_list, ans_list):\n","    assert len(pred_list) == len(ans_list)\n","    return sum(eval(p, a) for p, a in zip(pred_list, ans_list)) / len(pred_list)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_KxPZRjsJOp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595245778665,"user_tz":-480,"elapsed":547,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"af1f74df-3280-46bf-b162-3b77c18296c3"},"source":[" eval_all(predictions, ans)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9959266802443992"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"kaV5cGVupMAG","colab_type":"text"},"source":["---"]},{"cell_type":"code","metadata":{"id":"aE0_OemQsjse","colab_type":"code","colab":{}},"source":["p = set()\n","p.add(['asdf', 'asdf'])\n","print(p)\n","a = [['asdf', 'qwer'], ['']]\n","# eval_all(p,a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMJSK8ZO8siZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"error","timestamp":1595240292657,"user_tz":-480,"elapsed":936,"user":{"displayName":"李韋宗","photoUrl":"","userId":"06431049746033623123"}},"outputId":"c99398de-fb39-4811-db91-e8a651f24717"},"source":["\n","t = ['a', 'ghy']\n","t.append()\n","t"],"execution_count":54,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-b991ba467f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ghy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: append() takes exactly one argument (0 given)"]}]},{"cell_type":"code","metadata":{"id":"TgHzRmCJ-Rux","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}