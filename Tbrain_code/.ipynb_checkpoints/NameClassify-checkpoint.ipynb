{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from zhon.hanzi import non_stops\n",
    "import os\n",
    "import pickle\n",
    "from opencc import OpenCC\n",
    "# from transformers import RobertaForTokenClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import BertTokenizer , BertConfig , BertModel\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification,BertForPreTraining\n",
    "from torch.autograd import Variable\n",
    "from transformers import BertForPreTraining\n",
    "from torch import nn\n",
    "import json\n",
    "import requests\n",
    "pretrain_model_name = './chinese_roberta_wwm/'\n",
    "my_pretrain = './pretrain_roberta_on_TBdata'\n",
    "\n",
    "api_url = 'http://35.221.209.220/inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4426, 4)\n",
      "(491, 4)\n",
      "(4917, 4)\n",
      "[\"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['蔡開宇', '李訓成', '王為', '楊國文', '李應', '王宇正', '昱盛', '王均']\", \"['']\", \"['蔡英俊', '郭明賓', '嚴庚辰', '張永泉']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['徐耀昌', '謝昌年', '李瑞廷', '宋國鎮']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['牟明哲', '牟男', '陳學敏', '張女', '牟孝儀']\", \"['鍾男', '許祈文', '玉山卡', '阿伯許']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['黃世陽', '黃顯雄', '曹興誠', '宣明智', '錢利忠']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['林裕豐', '黃都坦誠', '劉昌松', '吳成', '黃淑頻', '呂東英', '曾國輝', '呂建安']\", \"['']\", \"['']\", \"['戴光育', '章氏', '蕭博文', '章家', '章民強', '章啟光', '賴永吉', '李恆隆', '章啟明']\", \"['張建生', '林男', '陳正達', '張宜豐', '黃志豪', '林宏彬', '吳昇儒']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['傅春生', '傅涉']\", \"['']\", \"['陳慰慈', '汪誠', '莊錫根', '莊妻', '莊男']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['朱國榮', '朱妻', '金寶山', '葉佳瑛', '劉慶珠']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['周麗真', '陳逢璿', '張志偉']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['旭順', '陳慰慈', '鄧媛', '蘇芸樂', '陳柏文', '林偉強', '張玉鳳', '孫幼英', '江國貴', '鍾素娥']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['賴俊吉']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['繆竹怡', '姚介修', '繆嫌', '蕫繆竹怡']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['陳永昌', '胡志明', 'Tran Vy', '陳偉和', '黃載文', '陳偉']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['鄭聖儒', '徐女', '吳昇儒', '鄭男']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['李立法', '歐啦', '林右正']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['黃昱凱', '莊琇媛']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['賴進坤']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['歐彥志', '張東耀', '陳俞雄', '楊文值', '楊哲灃', '楊家班', '楊士弘']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['朱國榮', '劉昌松', '林桂馨']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['楊國文', '張男', '張智凱', '李女']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['李全教', '李設定', '林不服']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['李威儀', '李與藍', '張文川', '李並', '王桂霜', '李向王', '藍秀琪']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['張男', '邱男未', '邱世忠', '邱男', '砲忠']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['吳左右', '吳女', '吳坤錦', '陳女', '楊政郡']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['柯賜海']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['珍菌堂', '張桂銘', '劉威甫']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['孔朝']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['曾國財', '鍾增林']\", \"['何培才']\", \"['']\", \"['']\", \"['']\", \"['上海仔', '葉清偉', '郭永鴻', 'Yeh Ching Wei', '姜維池']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['林敏志', '林男']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['因林', '吳男', '劉吉雄', '魯德海', '林輝宏', '判魯', '呂宗南', '裴振福', '張男', '黃捷', '楊則吞', '吳吞', '楊自立', '張建華', '張吞', '吳東明', '楊男']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['']\", \"['王懷恭', '劉慶侯']\", \"['']\", \"['']\", \"['']\"]\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"./tbrain/tbrain_train_split.csv\")\n",
    "train_df = pd.read_csv(\"./tbrain/tbrain_train.csv\")\n",
    "\n",
    "train_df = train_df.fillna('None')\n",
    "\n",
    "# test_df = pd.read_csv(\"./tbrain/tbrain_test_split.csv\")\n",
    "test_df = pd.read_csv(\"./tbrain/tbrain_test.csv\")\n",
    "#denny = pd.read_csv(\"./tbrain/tbrain_test_split.csv\")\n",
    "denny = pd.read_csv(\"./tbrain/denny_name.csv\")\n",
    "\n",
    "test_df = test_df.fillna('None')\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(all_df.shape)\n",
    "\n",
    "all_test_name = denny['name'].tolist()\n",
    "print(all_test_name)\n",
    "print(len(all_test_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '蔡開宇'\n",
      " '李訓成' '王為' '楊國文' '李應' '王宇正' '昱盛' '王均' '' '蔡英俊' '郭明賓' '嚴庚辰' '張永泉' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '徐耀昌' '謝昌年' '李瑞廷' '宋國鎮' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '牟明哲' '牟男' '陳學敏' '張女' '牟孝儀' '鍾男' '許祈文' '玉山卡'\n",
      " '阿伯許' '' '' '' '' '' '' '' '' '' '黃世陽' '黃顯雄' '曹興誠' '宣明智' '錢利忠' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '林裕豐' '黃都坦誠' '劉昌松' '吳成'\n",
      " '黃淑頻' '呂東英' '曾國輝' '呂建安' '' '' '戴光育' '章氏' '蕭博文' '章家' '章民強' '章啟光' '賴永吉'\n",
      " '李恆隆' '章啟明' '張建生' '林男' '陳正達' '張宜豐' '黃志豪' '林宏彬' '吳昇儒' '' '' '' '' '傅春生'\n",
      " '傅涉' '' '陳慰慈' '汪誠' '莊錫根' '莊妻' '莊男' '' '' '' '' '朱國榮' '朱妻' '金寶山' '葉佳瑛'\n",
      " '劉慶珠' '' '' '' '' '' '' '' '' '' '' '周麗真' '陳逢璿' '張志偉' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '旭順' '陳慰慈' '鄧媛' '蘇芸樂' '陳柏文' '林偉強' '張玉鳳' '孫幼英'\n",
      " '江國貴' '鍾素娥' '' '' '' '' '' '' '賴俊吉' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '繆竹怡' '姚介修' '繆嫌' '蕫繆竹怡' '' '' '' '' '' '' '' '' '' '' '' '陳永昌' '胡志明'\n",
      " 'Tran Vy' '陳偉和' '黃載文' '陳偉' '' '' '' '' '' '' '' '' '' '' '鄭聖儒' '徐女' '吳昇儒'\n",
      " '鄭男' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '李立法' '歐啦' '林右正' '' '' '' '' '' '' '' '黃昱凱' '莊琇媛' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '賴進坤' '' '' '' '' '' '歐彥志' '張東耀'\n",
      " '陳俞雄' '楊文值' '楊哲灃' '楊家班' '楊士弘' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '朱國榮' '劉昌松' '林桂馨' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '楊國文' '張男' '張智凱' '李女' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '李全教' '李設定' '林不服' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '李威儀' '李與藍' '張文川' '李並' '王桂霜' '李向王' '藍秀琪' '' '' '' '' '' '' '' '張男'\n",
      " '邱男未' '邱世忠' '邱男' '砲忠' '' '' '' '' '' '吳左右' '吳女' '吳坤錦' '陳女' '楊政郡' '' '' ''\n",
      " '' '' '' '' '' '' '' '柯賜海' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '珍菌堂' '張桂銘' '劉威甫' '' '' '' '' '孔朝' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '曾國財' '鍾增林' '何培才' '' '' '' '上海仔' '葉清偉' '郭永鴻' 'Yeh Ching Wei' '姜維池' '' ''\n",
      " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
      " '' '' '' '林敏志' '林男' '' '' '' '' '' '因林' '吳男' '劉吉雄' '魯德海' '林輝宏' '判魯' '呂宗南'\n",
      " '裴振福' '張男' '黃捷' '楊則吞' '吳吞' '楊自立' '張建華' '張吞' '吳東明' '楊男' '' '' '' '' '' ''\n",
      " '' '' '' '' '' '' '' '王懷恭' '劉慶侯' '' '' '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "all_name = []\n",
    "# for i in range(491):\n",
    "#     if len((all_test_name[i])) ==4:\n",
    "#         continue\n",
    "#     else:\n",
    "#         ckip_name = ast.literal_eval(all_test_name[i])\n",
    "#         if all_name == []:\n",
    "#             all_name= ckip_name\n",
    "#             all_name =np.array(all_name)\n",
    "#         else:\n",
    "#             ckip_name = np.array(ckip_name)\n",
    "#             all_name = np.concatenate((all_name,ckip_name),axis=0)\n",
    "for i in range(491):\n",
    "    ckip_name = ast.literal_eval(all_test_name[i])\n",
    "    if all_name == []:\n",
    "        all_name= ckip_name\n",
    "        all_name =np.array(all_name)\n",
    "    else:\n",
    "        ckip_name = np.array(ckip_name)\n",
    "        all_name = np.concatenate((all_name,ckip_name),axis=0)\n",
    "print(all_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4225,)\n",
      "(4225,)\n"
     ]
    }
   ],
   "source": [
    "name = pd.read_csv(\"./tbrain/train_name.csv\")\n",
    "\n",
    "x = name['name']\n",
    "y = name['ans']\n",
    "# l = 0\n",
    "# max_l = 0\n",
    "# for index,row in all_df.iterrows():\n",
    "#     name_li = ast.literal_eval(row['name'])\n",
    "#     ckip_name_li = ast.literal_eval(row['ckip_names'])\n",
    "\n",
    "#     if len(name_li) == 0:\n",
    "#         continue\n",
    "#     else:\n",
    "#         for name in ckip_name_li:\n",
    "#             x.append(name)\n",
    "#             l += len(name)\n",
    "#             if len(name) > max_l:\n",
    "#                 max_l = len(name)\n",
    "#             if name in name_li:\n",
    "#                 y.append(1)\n",
    "#             else:\n",
    "#                 y.append(0)\n",
    "                \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# print(l / x.shape[0])\n",
    "# print(max_l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./pretrain_roberta_on_TBdata/')\n",
    "config = BertConfig.from_pretrained('./pretrain_roberta_on_TBdata/'  + 'config.json',output_hidden_states=True)\n",
    "train_input_dict = tokenizer.batch_encode_plus(x, \n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=5,\n",
    "                                         return_special_tokens_mask=True,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, input_dict, y):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        y = self.y[idx]\n",
    "        return inputid , tokentype , attentionmask, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NameModel, self).__init__()\n",
    "        self.name_task = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(768,2)\n",
    "        )    \n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = x.double()\n",
    "        out = self.name_task(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model= torch.load('./TB_multispan/name_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NameModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 31.708\n",
      "[epoch 2] loss: 9.755\n",
      "[epoch 3] loss: 7.809\n",
      "[epoch 4] loss: 6.567\n",
      "[epoch 5] loss: 5.888\n",
      "[epoch 6] loss: 7.553\n",
      "[epoch 7] loss: 6.680\n",
      "[epoch 8] loss: 5.884\n",
      "[epoch 9] loss: 6.322\n",
      "[epoch 10] loss: 6.869\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "trainset = TrainDataset(train_input_dict, y)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = BertModel.from_pretrained('./pretrain_roberta_on_TBdata/',config=config)\n",
    "model = model.to(device)\n",
    "model.output_hidden_states = True\n",
    "model.eval()\n",
    "\n",
    "\n",
    "name_model = NameModel()\n",
    "name_model = name_model.to(device)\n",
    "name_model = name_model.double()\n",
    "name_model.train()\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(name_model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        tokens_tensors ,  segments_tensors , masks_tensors , labels = [t.to(device) for t in data]\n",
    "        \n",
    "        \n",
    "        bert_outputs = model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors)  \n",
    "        \n",
    "        pool_cls = bert_outputs[1]\n",
    "        pool_cls = pool_cls.double()\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = name_model(pool_cls)\n",
    "        \n",
    "        \n",
    "        labels = labels.long()\n",
    "        loss = loss_fn(logits,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    torch.save(name_model,'./TB_multispan/name_model.pkl')\n",
    "    print('[epoch %d] loss: %.3f' %(epoch + 1, running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, input_dict):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        return inputid , tokentype , attentionmask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(name_model.parameters(), lr=1e-3)\n",
    "def get_ans(test_name):\n",
    "    test_name = test_name\n",
    "    test_input_dict = tokenizer.encode_plus(test_name, \n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=5,\n",
    "                                         return_special_tokens_mask=True,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_tensors='pt')\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    model = BertModel.from_pretrained('./pretrain_roberta_on_TBdata/',config=config)\n",
    "    model = model.to(device)\n",
    "    model.output_hidden_states = True\n",
    "    model.eval()\n",
    "    name_model.eval()\n",
    "\n",
    "\n",
    "    bert_outputs = model(input_ids = test_input_dict['input_ids'].to(device), \n",
    "                        token_type_ids = test_input_dict['token_type_ids'].to(device), \n",
    "                        attention_mask= test_input_dict['attention_mask'].to(device))  \n",
    "\n",
    "    pool_cls = bert_outputs[1]\n",
    "    pool_cls = pool_cls.double()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = name_model(pool_cls)\n",
    "    \n",
    "    #is_name =torch.nn.Softmax(logits)\n",
    "    is_name = torch.argmax(logits)\n",
    "\n",
    "    return(is_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3fc462e16b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mput\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_ans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-c16c2878a7d9>\u001b[0m in \u001b[0;36mget_ans\u001b[0;34m(test_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m     bert_outputs = model(input_ids = test_input_dict['input_ids'].to(device), \n\u001b[1;32m     22\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                         attention_mask= test_input_dict['attention_mask'].to(device))  \n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpool_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "#排除重複的\n",
    "result =[]\n",
    "pred =[]\n",
    "all_name = np.unique(all_name)\n",
    "for data in all_name:\n",
    "    put =''\n",
    "    put =put+data\n",
    "    result.append(put)\n",
    "    ans=get_ans(put)\n",
    "    ans=ans.cpu()\n",
    "    ans=ans.numpy()\n",
    "    pred.append(ans)\n",
    "print(result)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "[['' '0']\n",
      " ['Tran Vy' '1']\n",
      " ['Yeh Ching Wei' '1']\n",
      " ['上海仔' '0']\n",
      " ['何培才' '1']\n",
      " ['傅春生' '1']\n",
      " ['傅涉' '0']\n",
      " ['判魯' '0']\n",
      " ['劉吉雄' '1']\n",
      " ['劉威甫' '1']\n",
      " ['劉慶侯' '1']\n",
      " ['劉慶珠' '1']\n",
      " ['劉昌松' '1']\n",
      " ['吳吞' '0']\n",
      " ['吳坤錦' '1']\n",
      " ['吳女' '0']\n",
      " ['吳左右' '0']\n",
      " ['吳成' '0']\n",
      " ['吳昇儒' '1']\n",
      " ['吳東明' '1']\n",
      " ['吳男' '0']\n",
      " ['呂宗南' '1']\n",
      " ['呂建安' '1']\n",
      " ['呂東英' '1']\n",
      " ['周麗真' '1']\n",
      " ['嚴庚辰' '0']\n",
      " ['因林' '0']\n",
      " ['姚介修' '1']\n",
      " ['姜維池' '1']\n",
      " ['孔朝' '1']\n",
      " ['孫幼英' '1']\n",
      " ['宋國鎮' '1']\n",
      " ['宣明智' '1']\n",
      " ['張吞' '0']\n",
      " ['張女' '0']\n",
      " ['張宜豐' '1']\n",
      " ['張建生' '1']\n",
      " ['張建華' '1']\n",
      " ['張志偉' '1']\n",
      " ['張文川' '1']\n",
      " ['張智凱' '1']\n",
      " ['張東耀' '1']\n",
      " ['張桂銘' '1']\n",
      " ['張永泉' '1']\n",
      " ['張玉鳳' '1']\n",
      " ['張男' '0']\n",
      " ['徐女' '0']\n",
      " ['徐耀昌' '1']\n",
      " ['戴光育' '1']\n",
      " ['旭順' '0']\n",
      " ['昱盛' '0']\n",
      " ['曹興誠' '1']\n",
      " ['曾國財' '1']\n",
      " ['曾國輝' '1']\n",
      " ['朱國榮' '1']\n",
      " ['朱妻' '0']\n",
      " ['李並' '0']\n",
      " ['李全教' '1']\n",
      " ['李向王' '1']\n",
      " ['李威儀' '1']\n",
      " ['李恆隆' '1']\n",
      " ['李應' '0']\n",
      " ['李瑞廷' '1']\n",
      " ['李立法' '1']\n",
      " ['李與藍' '0']\n",
      " ['李訓成' '1']\n",
      " ['李設定' '0']\n",
      " ['林不服' '0']\n",
      " ['林偉強' '1']\n",
      " ['林右正' '1']\n",
      " ['林宏彬' '1']\n",
      " ['林敏志' '1']\n",
      " ['林桂馨' '1']\n",
      " ['林男' '0']\n",
      " ['林裕豐' '1']\n",
      " ['林輝宏' '1']\n",
      " ['柯賜海' '1']\n",
      " ['楊則吞' '0']\n",
      " ['楊哲灃' '1']\n",
      " ['楊國文' '1']\n",
      " ['楊士弘' '1']\n",
      " ['楊家班' '0']\n",
      " ['楊政郡' '1']\n",
      " ['楊文值' '1']\n",
      " ['楊男' '0']\n",
      " ['楊自立' '1']\n",
      " ['歐啦' '0']\n",
      " ['歐彥志' '1']\n",
      " ['江國貴' '1']\n",
      " ['汪誠' '0']\n",
      " ['牟孝儀' '1']\n",
      " ['牟明哲' '1']\n",
      " ['牟男' '0']\n",
      " ['玉山卡' '0']\n",
      " ['王均' '0']\n",
      " ['王宇正' '1']\n",
      " ['王懷恭' '1']\n",
      " ['王桂霜' '1']\n",
      " ['王為' '0']\n",
      " ['珍菌堂' '0']\n",
      " ['砲忠' '0']\n",
      " ['章啟光' '1']\n",
      " ['章啟明' '1']\n",
      " ['章家' '0']\n",
      " ['章氏' '0']\n",
      " ['章民強' '1']\n",
      " ['繆嫌' '0']\n",
      " ['繆竹怡' '1']\n",
      " ['胡志明' '1']\n",
      " ['莊妻' '0']\n",
      " ['莊琇媛' '1']\n",
      " ['莊男' '0']\n",
      " ['莊錫根' '1']\n",
      " ['葉佳瑛' '1']\n",
      " ['葉清偉' '1']\n",
      " ['蔡英俊' '1']\n",
      " ['蔡開宇' '1']\n",
      " ['蕫繆竹怡' '0']\n",
      " ['蕭博文' '1']\n",
      " ['藍秀琪' '1']\n",
      " ['蘇芸樂' '1']\n",
      " ['裴振福' '1']\n",
      " ['許祈文' '1']\n",
      " ['謝昌年' '1']\n",
      " ['賴俊吉' '1']\n",
      " ['賴永吉' '1']\n",
      " ['賴進坤' '0']\n",
      " ['邱世忠' '1']\n",
      " ['邱男' '0']\n",
      " ['邱男未' '0']\n",
      " ['郭明賓' '1']\n",
      " ['郭永鴻' '1']\n",
      " ['鄧媛' '0']\n",
      " ['鄭男' '0']\n",
      " ['鄭聖儒' '1']\n",
      " ['金寶山' '1']\n",
      " ['錢利忠' '1']\n",
      " ['鍾增林' '1']\n",
      " ['鍾男' '0']\n",
      " ['鍾素娥' '1']\n",
      " ['阿伯許' '0']\n",
      " ['陳俞雄' '1']\n",
      " ['陳偉' '1']\n",
      " ['陳偉和' '1']\n",
      " ['陳女' '0']\n",
      " ['陳學敏' '1']\n",
      " ['陳慰慈' '1']\n",
      " ['陳柏文' '1']\n",
      " ['陳正達' '1']\n",
      " ['陳永昌' '1']\n",
      " ['陳逢璿' '1']\n",
      " ['魯德海' '0']\n",
      " ['黃世陽' '1']\n",
      " ['黃志豪' '1']\n",
      " ['黃捷' '0']\n",
      " ['黃昱凱' '1']\n",
      " ['黃淑頻' '1']\n",
      " ['黃載文' '1']\n",
      " ['黃都坦誠' '1']\n",
      " ['黃顯雄' '1']\n",
      " ['李女' '0']]\n"
     ]
    }
   ],
   "source": [
    "pred =np.array(pred)\n",
    "pred =pred.tolist()\n",
    "print(pred)\n",
    "\n",
    "data = np.array([result,label])\n",
    "data = data.swapaxes(0,1)\n",
    "print(data)\n",
    "df =pd.DataFrame(data)\n",
    "df.to_csv('./TB/for_Denny.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2402,  872, 2023,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'special_tokens_mask': tensor([[1, 0, 0, 0, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
