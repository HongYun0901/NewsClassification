{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4426, 4)\n",
      "(491, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import re\n",
    "from zhon.hanzi import stops\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "PRETRAINED_MODEL_NAME = \"hfl/rbtl3\" # RBTL3\n",
    "df_train = pd.read_csv('./tbrain/tbrain_train.csv')\n",
    "df_test = pd.read_csv('./tbrain/tbrain_test.csv')\n",
    "df_train = df_train.fillna('[\\'\\]')\n",
    "df_test = df_test.fillna('[\\'\\']')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(content):\n",
    "#     cc = OpenCC('t2s')\n",
    "    content = content.replace('\\n','。').replace('\\t','，').replace('!', '！').replace('?', '？')# erease white space cause English name error\n",
    "    content = re.sub(\"[+\\.\\/_,$%●▼►^*(+\\\"\\']+|[+——~@#￥%……&*（）★]\", \"\",content)\n",
    "    content = re.sub(r\"[%s]+\" %stops, \"。\",content)\n",
    "#     content = cc.convert(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(name, content):\n",
    "    # +1 for [CLS]\n",
    "    pos_list = [m.start()+1 for m in re.finditer(name, content)]\n",
    "    count = len(pos_list)\n",
    "    return pos_list , count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orgi_2_array(names, contents):\n",
    "    x = []\n",
    "    binary_y = []\n",
    "    BIO_labels = []\n",
    "    nFound_count = 0\n",
    "    name_count = 0\n",
    "    \n",
    "    for i in range(len(contents)):\n",
    "        content = contents[i]\n",
    "        content = clean_string(content)\n",
    "\n",
    "        # record names\n",
    "        # name = names[i] # single\n",
    "        name_list = names[i]\n",
    "        names_label = ast.literal_eval(name_list) # string to list\n",
    "        # debug\n",
    "        \n",
    "\n",
    "        # init pos label arr\n",
    "        BIO_label = np.full((512), 2) # initial to all 2 (outside)\n",
    "        \n",
    "        # no AML person\n",
    "        if(name_list == '[]'):\n",
    "            binary_y.append(0)\n",
    "            x.append(content)\n",
    "            BIO_label[0] = 0 # first position 0(begin)\n",
    "            BIO_labels.append(BIO_label)\n",
    "\n",
    "        else:\n",
    "            # initial position list\n",
    "            start_pos = []\n",
    "            end_pos = []\n",
    "\n",
    "            # if (True): # single\n",
    "            for name in names_label:\n",
    "              temp, count = find_all(name, content)\n",
    "              if(temp == []):\n",
    "  #                 print(name + ' find error in data', i)\n",
    "                  nFound_count += 1\n",
    "                  continue\n",
    "              for j in range(count):\n",
    "                start_pos.append(temp[j])\n",
    "                end_pos.append(temp[j] + len(name))\n",
    "\n",
    "#                  01234\n",
    "#                B 00100\n",
    "#                I 00011\n",
    "#                O 11000\n",
    "            if (i == 6):\n",
    "              print(start_pos)\n",
    "              print(end_pos)\n",
    "            for j in range(len(start_pos)):\n",
    "                if(start_pos[j] < 512 and end_pos[j] < 512):\n",
    "                    BIO_label[start_pos[j]] = 0\n",
    "                    BIO_label[start_pos[j]+1 : end_pos[j]] = 1\n",
    "            binary_y.append(1)\n",
    "            x.append(content)\n",
    "            BIO_labels.append(BIO_label)\n",
    "            \n",
    "\n",
    "    x = np.array(x)\n",
    "    binary_y = np.array(binary_y)\n",
    "    BIO_labels = np.array(BIO_labels)\n",
    "    \n",
    "    print('nFound: ', nFound_count)\n",
    "    print('name_count:', name_count)\n",
    "    print(x.shape)\n",
    "    print(binary_y.shape)\n",
    "#     print(begin_pos_labels.shape)\n",
    "#     print(inside_pos_labels.shape)\n",
    "#     print(outside_pos_labels.shape)\n",
    "    print(BIO_labels.shape)\n",
    "    return x, binary_y, BIO_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 151, 187, 191, 195, 183, 71]\n",
      "[4, 154, 190, 194, 198, 186, 74]\n",
      "nFound:  0\n",
      "name_count: 0\n",
      "(4426,)\n",
      "(4426,)\n",
      "(4426, 512)\n"
     ]
    }
   ],
   "source": [
    "names =  df_train['name']\n",
    "contents = np.array(df_train['full_content'].tolist())\n",
    "train_x, train_binary_y, train_bio_labels = orgi_2_array(names, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, input_dict, y , bio_labels):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "        self.bio_labels = bio_labels\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        bio_label = self.bio_labels[idx]\n",
    "        y = self.y[idx]\n",
    "        return inputid , tokentype , attentionmask, y , bio_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, input_dict):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        return inputid , tokentype , attentionmask, \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "\n",
    "PRETRAINED_MODEL_NAME = './chinese_xlnet_mid_pytorch/'\n",
    "\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "# 把input轉換成bert格式\n",
    "train_input_dict = tokenizer.batch_encode_plus(train_x, \n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=512,\n",
    "                                         return_special_tokens_mask=True,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model budling \"\"\"\n",
    "from transformers import BertModel, XLNetModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_utils import SequenceSummary\n",
    "\n",
    "class AMLPredictModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(AMLPredictModel, self).__init__()\n",
    "        self.bert = XLNetModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "        self.bert.output_hidden_states = True\n",
    "        self.classifier = nn.Sequential(\n",
    "                        nn.Linear(config.hidden_size, 2),\n",
    "        ) # binary classification\n",
    "        self.BIO_classifier = nn.Sequential(\n",
    "                        nn.Linear(config.hidden_size, 3),\n",
    "        ) # BIO tagging\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        \n",
    "        self.sequence_summary = SequenceSummary(config)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "#         position_ids=None,\n",
    "#         head_mask=None,\n",
    "#         inputs_embeds=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "#             position_ids=position_ids,\n",
    "#             head_mask=head_mask,\n",
    "#             inputs_embeds=inputs_embeds\n",
    "        )\n",
    "        \n",
    "\n",
    "       \n",
    "        have_AML = outputs[0] # pooled cls (cls token through 1 linear and tanh)\n",
    "        have_AML = self.sequence_summary(have_AML)\n",
    "        have_AML = self.classifier(have_AML)\n",
    "        \n",
    "        BIO = self.BIO_classifier(outputs[0]) # 512*HIDDENSIZE word vectors\n",
    "        BIO = self.softmax(BIO)\n",
    "        \n",
    "#         flag = 1\n",
    "        # debug\n",
    "#         if (flag):\n",
    "#             flag = 0\n",
    "#             print(\"forward output\")\n",
    "#             print(BIO)\n",
    "#             print(BIO_out)\n",
    "#             print(arg)\n",
    "#             print(\"---\")\n",
    "        \n",
    "        outputs = (have_AML, BIO) + outputs[2:]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    predictions_withoutmax = None\n",
    "    binary_correct = 0\n",
    "    total = 0\n",
    "    bio_correct = 0\n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0] # haveAML(binary classification)\n",
    "            after_softmax = nn.functional.softmax(logits.data, dim=1)\n",
    "            _, binary_pred = torch.max(after_softmax, 1)\n",
    "\n",
    "            temp = outputs[1]\n",
    "            bio_preds = torch.empty(temp.shape[0], 3, 512)\n",
    "            \n",
    "            for i in range(temp.shape[0]):  # run batchsize times\n",
    "                arg = temp[i].argmax(1) # 3*512 into class label\n",
    "                bio_preds[i] = arg\n",
    "\n",
    "            bio_preds = np.array(bio_preds)\n",
    "\n",
    "            # debug\n",
    "            print(\"get pred\")\n",
    "            print(\"b_pred \", binary_pred)\n",
    "            # print(binary_pred.shape)\n",
    "            # print(\"-----\")\n",
    "            # print(\"b_label \", data[3])\n",
    "            # print(data[3].shape)\n",
    "            print(\"BIO_labels \", data[4])\n",
    "            print(data[4].shape)\n",
    "            # print(\"---\")\n",
    "            print(\"BIO_pred \",bio_preds)\n",
    "            # print(bio_preds.shape)\n",
    "            # break\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                binary_labels = data[3]\n",
    "                total += binary_labels.size(0)\n",
    "                binary_correct += (binary_pred == binary_labels).sum().item()\n",
    "                bio_labels = data[4]\n",
    "                bio_correct += (bio_preds == bio_labels).sum().item()\n",
    "                # print(binary_correct)\n",
    "                # break\n",
    "\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = binary_pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, binary_pred))\n",
    "                \n",
    "            if predictions_withoutmax is None:\n",
    "                predictions_withoutmax = after_softmax\n",
    "            else:\n",
    "                predictions_withoutmax = torch.cat((predictions_withoutmax,after_softmax))\n",
    "    \n",
    "    if compute_acc:\n",
    "        binary_acc = binary_correct / total\n",
    "        bio_acc = bio_correct / total\n",
    "        return predictions, binary_acc, bio_acc\n",
    "    return predictions_withoutmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "\n",
      "name            module\n",
      "----------------------\n",
      "bert:word_embedding\n",
      "bert:layer\n",
      "bert:dropout\n",
      "classifier      Sequential(\n",
      "  (0): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "BIO_classifier  Sequential(\n",
      "  (0): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n",
      "sigmoid         Sigmoid()\n",
      "softmax         Softmax(dim=-1)\n",
      "sequence_summary SequenceSummary(\n",
      "  (summary): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (first_dropout): Identity()\n",
      "  (last_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model setting (training)\"\"\"\n",
    "from transformers import AdamW , XLNetConfig\n",
    "\n",
    "\n",
    "config = XLNetConfig.from_pretrained(PRETRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "BATCH_SIZE = 2\n",
    "trainSet = TrainDataset(train_input_dict, train_binary_y, train_bio_labels)\n",
    "trainLoader = DataLoader(trainSet, batch_size=BATCH_SIZE)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = AMLPredictModel(config)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5) # AdamW = BertAdam\n",
    "binary_loss_fct = nn.CrossEntropyLoss()\n",
    "weight = torch.FloatTensor([500,450,1]).cuda()\n",
    "BIO_loss_fct = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "# high-level 顯示此模型裡的 modules\n",
    "print(\"\"\"\n",
    "name            module\n",
    "----------------------\"\"\")\n",
    "for name, module in model.named_children():\n",
    "    if name == \"bert\":\n",
    "        for n, _ in module.named_children():\n",
    "            print(f\"{name}:{n}\")\n",
    "#             print(_)\n",
    "    else:\n",
    "        print(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type AMLPredictModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 3850.026, binary_loss: 1171.979, bio_loss: 2678.046\n",
      "[epoch 7] loss: 3846.388, binary_loss: 1169.730, bio_loss: 2676.658\n",
      "[epoch 8] loss: 3837.620, binary_loss: 1160.967, bio_loss: 2676.653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-10896446a71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         outputs = model(input_ids=tokens_tensors, \n\u001b[1;32m     31\u001b[0m                       \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                       attention_mask=masks_tensors)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mBIO_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7a54836753a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#             position_ids=position_ids,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             head_mask=head_mask,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             )\n\u001b[1;32m    944\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         )\n\u001b[1;32m    509\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# position based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ibnd,jbnd->bnij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_head\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_r_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_shift_bnij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# segment based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_shift_bnij\u001b[0;34m(x, klen)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m#       However, tracing doesn't like the nature of the slice, and if klen changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m#       during the run then it'll fail, whereas index_select will be fine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;31m# x = x[:, :, :, :klen]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" training \"\"\"\n",
    "model = model.to(device)\n",
    "model.train() ##########################\n",
    "\n",
    "EPOCHS = 10\n",
    "step = 0\n",
    "for epoch in range(5, EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    binary_running_loss = 0.0\n",
    "    BIO_running_loss = 0.0\n",
    "    for data in trainLoader:\n",
    "    # data = testSet[21] # test model\n",
    "    # if(True):\n",
    "        \n",
    "        tokens_tensors, segments_tensors, masks_tensors, \\\n",
    "        labels, BIO_label = [t.to(device) for t in data]\n",
    "\n",
    "      # tokens_tensors, segments_tensors, masks_tensors, labels, BIO_label = data\n",
    "      # tokens_tensors, segments_tensors, masks_tensors = data\n",
    "      # tokens_tensors = tokens_tensors.reshape((1,512)).to(device)\n",
    "      # segments_tensors = segments_tensors.reshape((1,512)).to(device)\n",
    "      # masks_tensors = masks_tensors.reshape((1,512)).to(device)\n",
    "      # labels = torch.tensor(labels).reshape((1)).to(device)\n",
    "      # BIO_label = torch.tensor(BIO_label).reshape((1,512)).to(device)\n",
    "\n",
    "      # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                      token_type_ids=segments_tensors, \n",
    "                      attention_mask=masks_tensors)\n",
    "\n",
    "        BIO_pred = outputs[1]\n",
    "        BIO_pred = torch.transpose(BIO_pred, 1, 2)\n",
    "      \n",
    "      # debug\n",
    "      # print(\"epoch output\")\n",
    "      # BIO_label[0][0] = 500\n",
    "      # BIO_label = BIO_label.squeeze()\n",
    "      # BIO_pred = BIO_pred.squeeze()\n",
    "      # print(BIO_label)\n",
    "      # print(BIO_label.shape)\n",
    "      # print(BIO_pred)\n",
    "      # print(BIO_pred.shape)\n",
    "      # print(outputs[0].shape)\n",
    "      # print(labels.shape)\n",
    "      # print(BIO_pred[0][0])\n",
    "      # print(BIO_pred[0][1])\n",
    "      # print(BIO_pred[0][2])\n",
    "      # break\n",
    "\n",
    "\n",
    "        binary_loss = binary_loss_fct(outputs[0], labels)\n",
    "      # print(BIO_pred.shape)\n",
    "      # print(BIO_label.shape)\n",
    "        BIO_loss = BIO_loss_fct(BIO_pred, BIO_label)\n",
    "      # print(binary_loss, BIO_loss)\n",
    "        loss = binary_loss + BIO_loss\n",
    "      # print(loss)\n",
    "      # break\n",
    "      \n",
    "      # backward\n",
    "      # loss.backward()\n",
    "      # optimizer.step()\n",
    "\n",
    "      # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        binary_running_loss += binary_loss.item()\n",
    "        BIO_running_loss += BIO_loss.item()\n",
    "      # if (step % 10 == 0):\n",
    "        # print('step %d total_loss: %.3f binary_loss: %.3f BIO_loss: %.3f' %\n",
    "        #     (step, running_loss, binary_running_loss, BIO_running_loss))\n",
    "        step += 1\n",
    "        \n",
    "    CHECKPOINT_NAME = './model/XLNet_bio_EPOCHES_' + str(epoch) + '.pkl'\n",
    "    torch.save(model, CHECKPOINT_NAME)\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    # _, binary_acc, bio_acc = get_predictions(model, trainLoader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, binary_loss: %.3f, bio_loss: %.3f' %\n",
    "          (epoch + 1, running_loss, binary_running_loss, BIO_running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['蔡開宇', '王宇正', '李訓成'],\n",
       " [''],\n",
       " ['張永泉', '郭明賓'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['李瑞廷'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['陳學敏', '牟孝儀'],\n",
       " ['許祈文'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['黃世陽', '黃顯雄'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['黃淑頻', '呂建安'],\n",
       " [''],\n",
       " [''],\n",
       " ['章民強', '章啟光', '章啟明'],\n",
       " ['張建生', '林宏彬', '張宜豐', '陳正達', '黃志豪'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['傅春生'],\n",
       " [''],\n",
       " ['莊錫根'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['朱國榮', '劉慶珠'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['周麗真', '張志偉', '陳逢璿'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['江國貴', '孫幼英', '林偉強', '蘇芸樂', '鍾素娥', '張玉鳳'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['賴俊吉'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['繆竹怡'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['陳偉', '黃載文'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['鄭聖儒'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['林右正'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['黃昱凱'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['賴進坤'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['楊士弘'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['林桂馨', '朱國榮'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['張智凱'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['李全教'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['王桂霜', '李威儀', '藍秀琪'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['邱世忠'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['吳坤錦'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['柯賜海'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['劉威甫', '張桂銘'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['孔朝'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['鍾增林', '曾國財'],\n",
       " ['何培才'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['葉清偉', '姜維池', '郭永鴻'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['林敏志'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['魯德海', '裴振福', '呂宗南', '楊自立', '劉吉雄', '林輝宏', '吳東明', '張建華'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['王懷恭'],\n",
       " [''],\n",
       " [''],\n",
       " ['']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_test['name'].tolist()\n",
    "ans = []\n",
    "for i in range(len(temp)):\n",
    "    t = ast.literal_eval(temp[i])\n",
    "    if (len(t) == 0):\n",
    "        t.append('')\n",
    "    ans.append(t)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nFound:  0\n",
      "name_count: 0\n",
      "(491,)\n",
      "(491,)\n",
      "(491, 512)\n"
     ]
    }
   ],
   "source": [
    "names =  df_test['name']\n",
    "contents = np.array(df_test['full_content'].tolist())\n",
    "test_x, test_binary_y, test_bio_labels = orgi_2_array(names, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dict = tokenizer.batch_encode_plus(test_x, \n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=512,\n",
    "                                         return_special_tokens_mask=True,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_2_string(tokens_tensors, have_AML, BIO_tagging, ckip_result):\n",
    "    result = []\n",
    "    if (have_AML.item() == 0):\n",
    "        result.append('')\n",
    "    else:\n",
    "        for j in range(1, 512):\n",
    "            if (BIO_tagging[j] == 0):\n",
    "                start = j\n",
    "                end = j + 1\n",
    "                while (end < 512 and BIO_tagging[end] == 1):\n",
    "                    end += 1\n",
    "                if (end > start + 1):\n",
    "                    s = tokenizer.decode(token_ids = tokens_tensors[start : end], skip_special_tokens = True)\n",
    "                    s = s.replace(' ', '')\n",
    "                    for k in range(len(ckip_result)):\n",
    "                        found = s.find(ckip_result[k])\n",
    "                        if (found != 1):\n",
    "                            result.append(ckip_result[k])\n",
    "    if (len(result) == 0):\n",
    "        result.append('')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, testLoader, BATCH_SIZE):\n",
    "  result = []\n",
    "  total_count = 0 # 第n筆data\n",
    "  with torch.no_grad():\n",
    "    for data in testLoader:\n",
    "      # 將所有 tensors 移到 GPU 上\n",
    "      if next(model.parameters()).is_cuda:\n",
    "        data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "      \n",
    "      # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "      # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "      tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "      outputs = model(input_ids=tokens_tensors, \n",
    "                  token_type_ids=segments_tensors, \n",
    "                  attention_mask=masks_tensors)\n",
    "      \n",
    "      # print(tokens_tensors, tokens_tensors.shape)\n",
    "      # print(outputs[0], outputs[0].shape)\n",
    "      # print(outputs[1], outputs[1].shape)\n",
    "      \n",
    "      count = min(outputs[0].shape[0], BATCH_SIZE)\n",
    "      for i in range(count):  # run batchsize times\n",
    "        have_AML = outputs[0][i].argmax()\n",
    "        BIO_pred = outputs[1][i].argmax(1) # 3*512 into class label\n",
    "        text_token = tokens_tensors[i]\n",
    "        ckip_names = df_test.loc[total_count, 'ckip_names']\n",
    "        ckip_names_list = ast.literal_eval(ckip_names) # string to list\n",
    "        r = bio_2_string(text_token, have_AML, BIO_pred, ckip_names_list)\n",
    "        # print(r)\n",
    "        result.append(r)\n",
    "        total_count += 1\n",
    "      \n",
    "        # print(text_token, text_token.shape)\n",
    "        # print(have_AML, have_AML.shape)\n",
    "        # print(BIO_pred, BIO_pred.shape)\n",
    "        # print(\"recover\", tokenizer.decode(token_ids = tokens_tensors[0][1:5], skip_special_tokens = True))\n",
    "      # break\n",
    "    # print(result)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-41d2a9d02fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pred = predictions.cpu().data.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b7035064952b>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model, testLoader, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     13\u001b[0m       outputs = model(input_ids=tokens_tensors, \n\u001b[1;32m     14\u001b[0m                   \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegments_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   attention_mask=masks_tensors)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m# print(tokens_tensors, tokens_tensors.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7a54836753a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#             position_ids=position_ids,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             head_mask=head_mask,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    940\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             )\n\u001b[1;32m    944\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         )\n\u001b[1;32m    509\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# attention probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mattn_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mattn_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"testing\"\"\"\n",
    "import torch\n",
    "from transformers import BertConfig , XLNetConfig\n",
    "\n",
    "PRETRAINED_MODEL_NAME = './chinese_xlnet_mid_pytorch/'\n",
    "config = XLNetConfig.from_pretrained(PRETRAINED_MODEL_NAME, output_hidden_states=True)\n",
    "model = AMLPredictModel(config)\n",
    "model = torch.load('./model/XLNet_bio_EPOCHES_.pkl')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "testSet = TestDataset(test_input_dict)\n",
    "testLoader = DataLoader(testSet, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "predictions = get_predictions(model, testLoader, BATCH_SIZE)\n",
    "\n",
    "# pred = predictions.cpu().data.numpy()\n",
    "# pred = np.argmax(pred, axis=1)\n",
    "# accuracy = (pred == test_binary_y).mean()\n",
    "# print('Your test accuracy is %.6f' % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(pred, ans):\n",
    "    if bool(pred) is not bool(ans):\n",
    "        return 0\n",
    "    elif not pred and not ans:\n",
    "        return 1\n",
    "    else:\n",
    "        pred = set(pred)\n",
    "        ans = set(ans)\n",
    "        interaction_len = len(pred & ans)\n",
    "        if interaction_len == 0:\n",
    "            return 0\n",
    "\n",
    "        pred_len = len(pred)\n",
    "        ans_len = len(ans)\n",
    "        return 2 / (pred_len / interaction_len + ans_len / interaction_len)\n",
    "\n",
    "\n",
    "def eval_all(pred_list, ans_list):\n",
    "    assert len(pred_list) == len(ans_list)\n",
    "    return sum(eval(p, a) for p, a in zip(pred_list, ans_list)) / len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_all(predictions, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
