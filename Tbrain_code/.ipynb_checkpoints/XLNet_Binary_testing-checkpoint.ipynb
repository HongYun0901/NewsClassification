{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from zhon.hanzi import non_stops, stops\n",
    "import os\n",
    "import pickle\n",
    "from opencc import OpenCC\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import BertTokenizer , BertConfig , BertModel , XLNetTokenizer, XLNetConfig , XLNetModel\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification,BertForPreTraining\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4917, 4)\n",
      "(491, 4)\n"
     ]
    }
   ],
   "source": [
    "# train_df = pd.read_csv(\"./tbrain/tbrain_train_split.csv\")\n",
    "train_df = pd.read_csv(\"./tbrain/tbrain_train.csv\")\n",
    "\n",
    "train_df = train_df.fillna('None')\n",
    "\n",
    "# test_df = pd.read_csv(\"./tbrain/tbrain_test_split.csv\")\n",
    "test_df = pd.read_csv(\"./tbrain/tbrain_test.csv\")\n",
    "\n",
    "train_df = pd.concat([train_df,test_df])\n",
    "\n",
    "test_df = test_df.fillna('None')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(content):\n",
    "#     cc = OpenCC('t2s')\n",
    "    content = content.replace('\\n','。').replace('\\t','，').replace('!', '！').replace('?', '？')# erease white space cause English name error\n",
    "    content = re.sub(\"[+\\.\\/_,$%●▼►^*(+\\\"\\']+|[+——~@#￥%……&*（）★]\", \"\",content)\n",
    "    content = re.sub(r\"[%s]+\" %stops, \"。\",content)\n",
    "#     content = cc.convert(content)\n",
    "    return content\n",
    "\n",
    "def cut_sent(para):\n",
    "    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para) \n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)  \n",
    "    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n",
    "    return para.split(\"\\n\")\n",
    "\n",
    "\n",
    "def combine_sentence(sentences):\n",
    "    li = []\n",
    "    string = ''\n",
    "    for k in range(len(sentences)):\n",
    "        sentence = sentences[k]\n",
    "        if len(string) + len(sentence) < 510:\n",
    "            string = string + sentence\n",
    "        else:\n",
    "#             原本是空的代表sentences太常\n",
    "            if string == '':\n",
    "                n = 510\n",
    "                tmp_li = [sentence[i:i+n] for i in range(0, len(sentence), n)]\n",
    "                string = tmp_li.pop(-1)\n",
    "                li = li + tmp_li\n",
    "            else:\n",
    "                li.append(string)\n",
    "                string = sentence\n",
    "    if(string != ''):\n",
    "        li.append(string)\n",
    "    return li\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4917,)\n",
      "(4917,)\n",
      "(0,)\n",
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "names =  train_df['name'].tolist()\n",
    "contents = np.array(train_df['full_content'].tolist())\n",
    "ckip_names = train_df['ckip_names'].tolist()\n",
    "x = []\n",
    "binary_y = []\n",
    "names_y  = []\n",
    "content_all_names = []\n",
    "start_pos_labels = []\n",
    "end_pos_labels = []\n",
    "for i in range(len(contents)):\n",
    "    content = contents[i]\n",
    "    content = clean_string(content)\n",
    "    content_ckip_names = ast.literal_eval(ckip_names[i])\n",
    "\n",
    "    if(content=='nan'):\n",
    "        continue\n",
    "\n",
    "    \n",
    "    name_li  = ast.literal_eval(names[i])\n",
    "    if(len(name_li) == 0 ):\n",
    "#         content切句 \n",
    "        x.append(content)\n",
    "        binary_y.append(0)\n",
    "#         split_content = cut_sent(content)\n",
    "#         chunks = combine_sentence(split_content)\n",
    "        \n",
    "#         for chunk in chunks:\n",
    "#             start_pos_label = np.zeros(512)\n",
    "#             end_pos_label = np.zeros(512)\n",
    "#             binary_y.append(0)\n",
    "#             start_pos_label[0] = 1\n",
    "#             end_pos_label[0] = 1\n",
    "#             x.append(chunk)\n",
    "#             start_pos_labels.append(start_pos_label)\n",
    "#             end_pos_labels.append(end_pos_label)\n",
    "#             content_all_names.append(content_ckip_names)\n",
    "        \n",
    "    else:\n",
    "        x.append(content)\n",
    "        binary_y.append(1)\n",
    "        \n",
    "#         for name in name_li:\n",
    "        \n",
    "        \n",
    "#             name = name.replace('\\n','').replace('\\t','').replace(' ','')\n",
    "#             #  content切句 \n",
    "            \n",
    "#             _pos = 0\n",
    "#             while True:\n",
    "#                 start_pos = content.find(name,_pos)\n",
    "#                 if(start_pos == -1):\n",
    "#                     break\n",
    "#                 start_pos += 1\n",
    "#                 _pos = start_pos\n",
    "#                 end_pos = start_pos + len(name)\n",
    "\n",
    "#                 if(start_pos < 512 and end_pos < 512 ):\n",
    "#                     binary_y.append(1)\n",
    "#                     x.append(content)\n",
    "\n",
    "#                     start_pos_label = np.zeros(512)\n",
    "#                     end_pos_label = np.zeros(512)\n",
    "#                     start_pos_label[start_pos] = 1\n",
    "#                     end_pos_label[end_pos] = 1\n",
    "\n",
    "#                     start_pos_labels.append(start_pos_label)\n",
    "#                     end_pos_labels.append(end_pos_label)\n",
    "#                     content_all_names.append(content_ckip_names)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "train_x = np.array(x)\n",
    "train_binary_y = np.array(binary_y)\n",
    "train_start_pos_labels = np.array(start_pos_labels)\n",
    "train_end_pos_labels = np.array(end_pos_labels)\n",
    "train_ckip_names = np.array(content_all_names)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_binary_y.shape)\n",
    "print(train_start_pos_labels.shape)\n",
    "print(train_end_pos_labels.shape)\n",
    "print(train_ckip_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "model_path  = './chinese_xlnet_mid_pytorch/'\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained(model_path)\n",
    "\n",
    "train_input_dict = tokenizer.batch_encode_plus(train_x, \n",
    "                                         add_special_tokens=True,\n",
    "                                         max_length=512,\n",
    "                                         return_special_tokens_mask=True,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_utils import SequenceSummary\n",
    "\n",
    "class XLNetBinrayClassifier(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(XLNetBinrayClassifier, self).__init__()\n",
    "        self.sequence_summary = SequenceSummary(config)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, 2),\n",
    "        )\n",
    "\n",
    "\n",
    "#             \n",
    "    def forward(self, x):\n",
    "        x = self.sequence_summary(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, input_dict, y):\n",
    "        self.input_ids = input_dict['input_ids']\n",
    "        self.token_type_ids = input_dict['token_type_ids']\n",
    "        self.attention_mask = input_dict['attention_mask']\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        inputid = self.input_ids[idx]\n",
    "        tokentype = self.token_type_ids[idx]\n",
    "        attentionmask = self.attention_mask[idx]\n",
    "        y = self.y[idx]\n",
    "        return inputid , tokentype , attentionmask, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "train acc: 0.954037014439699\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "trainset = TrainDataset(train_input_dict, \n",
    "                        train_binary_y)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print(\"device:\", device)\n",
    "\n",
    "model_path  = './chinese_xlnet_mid_pytorch/'\n",
    "config = XLNetConfig.from_pretrained(model_path + 'config.json',output_hidden_states=True)\n",
    "model = XLNetModel.from_pretrained(model_path,config=config)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "binary_model = XLNetBinrayClassifier(config)\n",
    "binary_model = binary_model.to(device)\n",
    "binary_model = binary_model.double()\n",
    "binary_model.load_state_dict(torch.load('./TB_multispan/XLNet_binary_alldataset_12.pkl'))\n",
    "binary_model.eval()\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# EPOCHS = 10\n",
    "# optimizer = torch.optim.Adam(binary_model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        \n",
    "        tokens_tensors ,  segments_tensors , masks_tensors , binary_y  = [t.to(device) for t in data]\n",
    "        \n",
    "        bert_outputs = model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors)\n",
    "        \n",
    "\n",
    "        bert_all_768 = bert_outputs[0]\n",
    "        total += bert_all_768.size()[0]\n",
    "        logits = binary_model(bert_all_768.double())\n",
    "        logits = torch.argmax(logits, dim=-1)\n",
    "        correct += (logits == binary_y).sum().item()\n",
    "        \n",
    "    print('train acc:' , correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
