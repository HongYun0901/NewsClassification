{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "(35546,)\n",
      "(35546, 7)\n",
      "Word2Vec(vocab=266873, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector,Input\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.layers import Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Add,Concatenate,BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#參數\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "\n",
    "\n",
    "print (keras.__version__)\n",
    "\n",
    "column_names = ['type','title','text']\n",
    "df = pd.read_csv('./all_after_mapping.tsv',sep='\\t',names=column_names)\n",
    "labels = df['type'].values\n",
    "labels = np.array(labels)\n",
    "print(labels.shape)\n",
    "labels = np_utils.to_categorical(labels)\n",
    "print(labels.shape)\n",
    "tokenlizeword = np.load('./tokenlizeword0225_nopunct.npy',allow_pickle=True)\n",
    "wmodel=Word2Vec.load('./word2vec.model')\n",
    "print(wmodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding done\n"
     ]
    }
   ],
   "source": [
    "#x_train=文章數*最大字數*300維\n",
    "x_train = []\n",
    "for k in range(tokenlizeword.shape[0]):\n",
    "# every article have 每篇文章最多幾個字 * 300維 embedding matrix\n",
    "    embedding_matrix = np.zeros((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))\n",
    "    for i in range(len(tokenlizeword[k])):\n",
    "        if(i>=MAX_SEQUENCE_LENGTH):\n",
    "            break\n",
    "        embedding_matrix[i] = wmodel[tokenlizeword[k][i]]\n",
    "    x_train.append(embedding_matrix)\n",
    "\n",
    "print(\"embedding done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "put = np.load('./XML_data.npy')\n",
    "# put= []\n",
    "# for k in range(tokenlizeword.shape[0]):\n",
    "#     put_matrix=np.zeros((EMBEDDING_DIM,MAX_SEQUENCE_LENGTH))\n",
    "#     for i in range(EMBEDDING_DIM):\n",
    "#         put_vector=np.zeros(MAX_SEQUENCE_LENGTH)\n",
    "#         for j in range(MAX_SEQUENCE_LENGTH):\n",
    "#             put_vector[j]=x_train[k][j][i]\n",
    "#         put_matrix[i]=put_vector\n",
    "#     put.append(put_matrix)\n",
    "#     print(k)\n",
    "    \n",
    "# put=np.array(put)\n",
    "# print(put)\n",
    "# np.save('XML_data',put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35546, 7)\n",
      "(5000, 300, 512)\n",
      "(5000, 300, 512)\n",
      "(25546, 300, 512)\n",
      "60%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dev_x = put[:5000]\n",
    "dev_y = labels[:5000]\n",
    "\n",
    "test_x = put[5000:10000]\n",
    "test_y = labels[5000:10000]\n",
    "\n",
    "train_x = put[10000:]\n",
    "train_y = labels[10000:]\n",
    "# !ls\n",
    "print(labels.shape)\n",
    "print(dev_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_x.shape)\n",
    "\n",
    "print(\"60%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - simplified convolutional neural network\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 298, 512)          786944    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 99, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 97, 512)           786944    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 30, 512)           786944    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               655488    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 3,017,223\n",
      "Trainable params: 3,017,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25546 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "25546/25546 [==============================] - 118s 5ms/step - loss: 1.2235 - acc: 0.5650 - val_loss: 0.9335 - val_acc: 0.7118\n",
      "Epoch 2/5\n",
      "25546/25546 [==============================] - 111s 4ms/step - loss: 0.5056 - acc: 0.8278 - val_loss: 0.8406 - val_acc: 0.7402\n",
      "Epoch 3/5\n",
      "25546/25546 [==============================] - 113s 4ms/step - loss: 0.3850 - acc: 0.8673 - val_loss: 0.9097 - val_acc: 0.7502\n",
      "Epoch 4/5\n",
      "25546/25546 [==============================] - 111s 4ms/step - loss: 0.2582 - acc: 0.9123 - val_loss: 1.0226 - val_acc: 0.7480\n",
      "Epoch 5/5\n",
      "25546/25546 [==============================] - 113s 4ms/step - loss: 0.1415 - acc: 0.9514 - val_loss: 1.0818 - val_acc: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9368559f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sequence_input = Input(shape=(EMBEDDING_DIM,MAX_SEQUENCE_LENGTH), dtype='float32')\n",
    "l_cov1= Conv1D(512, 3, activation='relu')(sequence_input)\n",
    "l_pool1 = MaxPooling1D(3)(l_cov1)\n",
    "l_cov2 = Conv1D(512, 3, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(3)(l_cov2)\n",
    "l_cov3 = Conv1D(512, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(3)(l_cov3)  # global max pooling\n",
    "l_drop2 = Dropout(0.5)(l_pool3)\n",
    "l_flat = Flatten()(l_drop2)\n",
    "\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(7, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adamax',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - simplified convolutional neural network\")\n",
    "model.summary()\n",
    "model.fit(train_x, train_y, validation_data = (dev_x,dev_y),epochs=5, batch_size=50)\n",
    "# model.fit(train_x, train_y, validation_split = 0.2,epochs=5, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(test_x,batch_size=50)\n",
    "pred=np.argmax(pred, axis=1)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3831\n",
      "0.7662\n"
     ]
    }
   ],
   "source": [
    "#驗證\n",
    "correct=0 #對的有幾個\n",
    "for i in range(5000):\n",
    "    if test_y[i][pred[i]]==1.0:\n",
    "        correct = correct+1\n",
    "print(correct)\n",
    "acc=correct/5000\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
